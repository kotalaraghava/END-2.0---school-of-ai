{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2 Session 4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotalaraghava/END-2.0---school-of-ai/blob/master/Encoder_decoder_session6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAM_ur4Rw8VK",
        "outputId": "ff0fa6fa-3a3a-438f-e0cc-3c72d774eddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q spacy==3.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 12.7MB 241kB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.1MB 46.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 60.5MB/s \n",
            "\u001b[?25h  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBvIT0azx8YA"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SPhj6gnAnT2"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edVAOwR6vpmA"
      },
      "source": [
        "\n",
        "def load_data(opt):\n",
        "    # use torchtext to load data, no need to download dataset\n",
        "    print(\"loading {} dataset\".format(opt.dataset))\n",
        "    # set up fields\n",
        "    text = data.Field(lower=True, include_lengths=True, batch_first=True, fix_length=opt.max_seq_len)\n",
        "    label = data.Field(sequential=False)\n",
        "\n",
        "    # make splits for data\n",
        "    train, test = datasets.IMDB.splits(text, label)\n",
        "\n",
        "    # build the vocabulary\n",
        "    text.build_vocab(train, vectors=GloVe(name='6B', dim=300))\n",
        "    label.build_vocab(train)\n",
        "\n",
        "    # print vocab information\n",
        "    print('len(TEXT.vocab)', len(text.vocab))\n",
        "    print('TEXT.vocab.vectors.size()', text.vocab.vectors.size())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwn4oStE6PzV",
        "outputId": "18d23594-9785-4837-a63a-a1a23421cfad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:06<00:00, 13.8MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DLJ86m56Xdn",
        "outputId": "46afe5ef-246a-4fbe-a9c1-7777fb99f87b"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXTWwqXA6rP2",
        "outputId": "8d7915e3-0347-45f8-fb21-4181785b3fe3"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['To', 'finally', 'see', 'what', 'many', 'consider', 'to', 'be', 'the', 'greatest', 'women', '-', 'in', '-', 'prison', 'film', 'of', 'all', 'time', ',', 'I', 'felt', 'like', 'I', 'had', 'accomplished', 'something', 'as', 'ridiculous', 'as', 'that', 'sounds', '.', 'Boy', ',', 'it', 'sure', 'contained', 'the', 'elements', 'I', 'expected', ',', 'and', 'delivered', 'so', 'much', 'more', '.', 'A', 'constant', 'I', \"'m\", 'discovering', 'in', 'these', 'films', 'is', 'the', 'toughness', 'and', 'grit', 'of', 'the', 'actresses', 'in', 'the', 'roles', 'of', 'prisoners', 'preparing', 'for', 'escape', 'while', 'their', 'threshold', ',', 'tolerance', ',', 'and', 'resolve(', '..', 'not', 'to', 'mention', 'sanity)being', 'tested', 'by', 'their', 'superiors', '.', 'While', 'most', 'of', 'them', 'were', 'hired', 'for', 'the', 'way', 'they', 'look', 'naked', ',', 'because', 'the', 'nature', 'of', 'the', 'genre', 'demands', 'such', 'gratuitous', 'elements', ',', 'something', 'else', 'emerges', ',', 'other', 'attributes', ',', 'such', 'as', 'attitude', 'and', 'guts', ',', 'that', 'I', 'ultimately', 'respond', 'to.<br', '/><br', '/>This', ',', 'as', 'you', 'may', 'know', 'all', 'too', 'well', ',', 'was', 'Demme', \"'s\", 'debut', 'for', 'his', 'mentor', 'Roger', 'Corman', ',', 'and', 'he', 'provides', 'the', 'target', 'audience', 'with', 'exactly', 'what', 'they', 'desire', 'while', 'putting', 'his', 'own', 'stamp', 'on', 'the', 'proceedings', '.', 'For', 'instance', ',', 'there', 'are', 'bizarre', 'dreams', 'certain', 'characters', 'have', 'which', 'define', 'their', 'current', 'psychological', 'states(', '..', 'there', \"'s\", 'a', 'particular', 'number', 'featuring', 'warden', 'Barbara', 'Steele', 'where', 'she', 'reminded', 'me', 'of', 'Alex', 'de', 'Large', 'of', 'A', 'Clockwork', 'Orange).<br', '/><br', '/>The', 'film', 'has', 'female', 'prisoners', 'planning', 'a', 'daring', 'escape', ',', 'tired', 'of', 'the', 'crazed', 'antics', 'of', 'their', 'wheel', '-', 'chair', 'bound', 'warden', 'and', 'her', 'nutty', 'prison', 'doc', ',', 'Randolph(Warren', 'Miller', ')', '.', 'Juanita', 'Brown', 'is', 'Maggie', ',', 'the', 'tough', ',', 'sassy', 'sister', 'who', 'is', 'fed', 'up', 'with', 'the', 'environment', 'and', 'will', 'do', 'whatever', 'it', 'takes', 'to', 'get', 'out', '.', 'She', \"'s\", 'the', 'one', 'all', 'the', 'girls', 'fear', 'to', 'cross', '.', 'Erica', 'Gavin', 'is', 'Jacqueline', 'Wilson', ',', 'the', 'newest', 'prisoner', 'who', 'was', 'busted', 'by', 'police', 'and', 'sentenced', 'for', 'the', 'murder', 'of', 'a', 'cop', ',', 'unwilling', 'to', 'give', 'up', 'the', 'names', 'of', 'those', 'she', 'was', 'involved', 'with', '.', 'Roberta', 'Collins', 'is', 'Belle', ',', 'a', 'serial', 'kleptomaniac', ',', 'best', 'pals', 'with', 'Pandora(Ella', 'Reid', ')', '.', 'Belle', 'becomes', 'the', 'obsession', 'of', 'Randolph', 'who', 'promises', 'Superintendent', 'McQueen(Steele)that', 'through', 'a', 'surgical', 'procedure', 'he', 'can', 'remove', 'her', 'violent', 'tendencies', '.', 'Drugging', 'her', 'up', ',', 'Randolph', 'takes', 'nude', 'pictures', 'and', 'sodomizes', 'her', ',', 'whimpering', 'like', 'a', 'little', 'girl', 'due', 'to', 'his', 'own', 'mental', 'deficiencies', 'while', 'hugging', 'her', 'naked', 'body', 'in', 'his', 'arms', '.', 'Cheryl', 'Rainbeaux', 'Smith', 'is', 'Lavelle', ',', 'in', 'prison', 'for', 'life', 'for', 'murdering', 'a', 'scumbag', 'whose', 'relative', 'was', 'a', 'Senator', '.', 'Lavelle', 'receives', 'work', 'in', 'Randolph', \"'s\", 'office', 'and', 'is', 'the', 'one', 'responsible', 'for', 'relating', 'his', 'dirty', 'antics', 'to', 'Pandora', '.', 'Demme', 'effectively', 'builds', 'the', 'movie', 'to', 'the', 'expected', 'finale', 'as', 'a', 'planned', 'break', '-', 'out', ',', 'using', 'those', 'behind', 'the', 'various', 'traumas', 'inflicted', 'on', 'the', 'prisoners', 'as', 'hostages', ',', 'with', 'gunfire', 'erupting.<br', '/><br', '/>I', 'was', 'quite', 'impressed', 'with', 'the', 'photographic', 'work', 'of', 'long', 'time', 'Demme', 'collaborator', ',', 'cinematographer', 'Tak', 'Fujimoto', ',', 'as', 'he', 'is', 'able', 'to', 'establish', 'some', 'visually', 'arresting', 'moments', 'within', 'the', 'cramped', 'confines', 'of', 'the', 'prison', ',', 'cells', 'and', 'rooms', ',', 'not', 'an', 'easy', 'task', '.', 'The', 'prison', 'is', 'appropriately', 'crummy', 'and', 'the', 'girls', ',', 'despite', 'being', 'quite', 'attractive', ',', 'look', 'the', 'part', 'of', 'desperate', 'inmates', 'longing', ',', 'yearning', 'from', 'the', 'very', 'pits', 'of', 'their', 'souls', ',', 'to', 'escape', 'such', 'horrid', 'entrapment', '.', 'Steele', 'is', 'superb', 'as', 'the', 'warden', ',', 'understanding', 'how', 'to', 'take', 'the', 'role', 'close', 'to', 'the', 'brink', 'without', 'going', 'to', 'far', ',', 'candidly', 'able', 'to', 'express', 'the', 'madness', 'of', 'her', 'repressed', 'character', 'within', 'a', 'restraint', '..', 'notice', 'how', 'she', 'works', 'her', 'glasses', 'and', 'settles', 'herself', 'without', 'blowing', 'her', 'top', 'particularly', 'when', 'certain', 'behaviors', 'she', 'has', 'contempt', 'for', 'push', 'her', 'teetering', 'to', 'the', 'edge', '.', 'Cale', \"'s\", 'bluesy', 'score', 'is', 'incredibly', 'depressing', ',', 'while', 'also', 'casting', 'a', 'wink', 'to', 'the', 'audience', 'that', 'the', 'movie', 'is', 'still', 'fun', '-', 'and', '-', 'games', '..', 'I', 'think', 'Cale', \"'s\", 'score', 'mirrors', 'Demme', \"'s\", 'handling', 'of', 'the', 'material', '.', 'Cale', 'and', 'Demme', \"'s\", 'partnership', 'is', 'an', 'uncanny', 'alliance', 'that', 'presents', 'the', 'setting', 'as', 'a', 'sad', ',', 'isolating', ',', 'oppressive', 'place', ',', 'while', ',', 'almost', 'simultaneously', ',', 'showcasing', 'a', 'humorous', 'tone', 'that', 'permeates', 'due', 'to', 'the', 'colorful', 'characters', 'thanks', 'in', 'part', 'to', 'the', 'personalities', 'of', 'the', 'cast', '.', 'My', 'favorite', 'scene', 'happens', 'outside', 'the', 'prison', ',', 'as', 'two', 'of', 'our', 'girls(', '..', 'joining', 'forces', 'with', 'a', 'third)interrupt', 'a', 'bank', 'robbery', 'already', 'in', 'progress', '..', 'the', 'kicker', 'is', 'it', 'was', 'a', 'bank', 'they', 'were', 'planning', 'to', 'rob', '!', 'As', 'you', 'might', 'expect', ',', 'you', 'get', 'naked', 'women', 'in', 'showers', ',', 'prisoner', 'in', 'solitary', ',', 'a', 'cat', 'fight', ',', 'shootouts', ',', 'attempted', 'escapes', 'which', 'go', 'awry', ',', 'and', 'other', 'exploitative', 'elements(', '..', 'such', 'as', 'a', 'horrifying', 'shock', 'therapy', 'session', ',', 'not', 'to', 'exclude', 'the', 'shocking', 'aforementioned', 'sequence', 'where', 'the', 'screwy', 'doc', 'takes', 'advantage', 'of', 'Belle', ')', '.', 'Interesting', 'enough', ',', 'Demme', 'relates', 'the', 'film', 'to', 'the', 'audience', 'without', 'a', 'whiff', 'of', 'pretension', ',', 'understanding', 'exactly', 'the', 'kind', 'of', 'movie', 'he', 'was', 'making', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HMVqiZd6tR0"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOeQ6KpP7M-0",
        "outputId": "3fc63e51-ffb6-4ba8-de79-d2d6a7e42460"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixkM1jQ7TB-"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD4SFKnc7g0D",
        "outputId": "5f09015f-cbfa-4f95-e4a2-bea83020fb80"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttKvFTCQ7isK",
        "outputId": "cbebe588-f332-4664-cf66-fcc091c83f71"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 202434), (',', 191486), ('.', 165173), ('a', 109359), ('and', 109277), ('of', 100783), ('to', 93524), ('is', 76351), ('in', 61225), ('I', 54232), ('it', 53664), ('that', 49264), ('\"', 44661), (\"'s\", 43165), ('this', 42455), ('-', 37795), ('/><br', 35633), ('was', 34935), ('as', 30466), ('with', 29838)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZXIsIV47mlI",
        "outputId": "15a36e7e-bcd7-419b-991c-2b000f4fe69a"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbx3T9-7x4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33956fb-37ad-4c68-8f5f-3cc9060505a0"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3gBfP6mEJ_0"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ZQQV1-ELZf"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, (hidden, cn) = self.lstm(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        hidden = hidden[-1,:,:]\n",
        "        # import pdb\n",
        "        # pdb.set_trace()\n",
        "        # output, (hidden, b) = self.lstm(embedded)\n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0_X5kSwENad"
      },
      "source": [
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdGb8dKBEO2x",
        "outputId": "b71bbf47-bc73-4121-98e0-734c6b13fed5"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,867,049 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAeEtXiJEQCj"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Utp4-qAERRG"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyAXf58FESdL"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4yNiGXQETh9"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1iGJW1wEUrL"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        # import pdb\n",
        "        # pdb.set_trace()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNQxQS3tEWUW"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVM8MtV6EYIw"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ5KZmM4EZXW"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIiKAJMaEbKO",
        "outputId": "eb1da8b2-c963-4944-9e4d-c8957147a051"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.724 | Test Acc: 56.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G024NssCEcj0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}