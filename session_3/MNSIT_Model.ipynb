{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5_6143279572453426035.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWxvC_yK1RDL"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-gTxxe6jYit"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from random import randint\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYaFjvbw0jnO"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zwxNmICjby_"
      },
      "source": [
        "dropout_value = 0.06\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(in_channels=1, out_channels=12, kernel_size=(3, 3), bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value), # output_size = 26\n",
        "            \n",
        "        )\n",
        "      \n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value), #output_size = 24\n",
        "            \n",
        "        )\n",
        "\n",
        "        \n",
        "        self.convblock3 = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value), #output_size = 22\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(2, 2) # output_size = 11\n",
        "\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "          \n",
        "\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value), # output_size = 9   \n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "        self.convblock5 = nn.Sequential(   \n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), bias=False), \n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value),  # output_size = 7     \n",
        "            \n",
        "        )\n",
        "\n",
        "        self.convblock6 = nn.Sequential(   \n",
        "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=(3, 3), bias=False), \n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value),   # output_size = 5     \n",
        "            \n",
        "        )\n",
        "\n",
        "        self.convblock7 = nn.Sequential(   \n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding = 1,bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value),       # output_size = 5  \n",
        "            \n",
        "        )\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5) # output_size = 1*1*16\n",
        "        ) \n",
        "\n",
        "\n",
        "        self.convblock8 = nn.Sequential(   \n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1),bias=False), # output_size = 1 * 1* 10\n",
        "                      \n",
        "        )\n",
        "        self.addition_layer1 = nn.Linear(in_features=2, out_features=10)\n",
        "        self.addition_layer2 = nn.Linear(in_features=10, out_features=30)\n",
        "        self.addition_out_layer = nn.Linear(in_features=30, out_features=1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, random_input):\n",
        "\n",
        "        #print(f'x= {x.shape}')\n",
        "        number_result = random_input\n",
        "        x = self.convblock1(x)   \n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock8(x)\n",
        "        outputImage = x.view(-1, 10)\n",
        "        # outputImage = torch.flatten(x, start_dim=1)\n",
        "        imageOutput = torch.argmax(outputImage, dim=1)\n",
        "        image_value_and_number  = torch.stack((imageOutput.float(), random_input), dim=1)\n",
        "        # print(f' concatenated = {image_value_and_number.shape}')\n",
        "        #print(f'imageOutPut = {imageOutput} outputshape = {imageOutput.shape}')\n",
        "\n",
        "\n",
        "        #print(f'x shape {x.shape}')\n",
        "        y=0\n",
        "        addition_result = self.addition_layer1(image_value_and_number)\n",
        "        addition_result = self.addition_layer2(addition_result)\n",
        "        addition_result = self.addition_out_layer(addition_result)\n",
        "        # print(f'additionalInput = {addition_result}, ishape = {addition_result.shape}')\n",
        "        # if random_input != None:\n",
        "        #   y = 0\n",
        "        #   print(f'r= {random_input.shape}')\n",
        "        #   #random_input = F.one_hot(random_input, num_classes=10)\n",
        "        #   #random_input = random_input.reshape(-1,1,1,10);\n",
        "        #   #print(f'f= {random_input.shape}')\n",
        "        #   #print(f'random_input = {random_input}')\n",
        "        #   #random_input = F.one_hot(random_input, num_classes=10)\n",
        "        #   #addition_result = self.addition_layer1(torch.tensor(random_input, dtype=torch.float32,));\n",
        "        #   #addition_result = self.addition_layer2(addition_result);\n",
        "        #   #addition_result = self.addition_out_layer(addition_result);\n",
        "        #   #number_result = addition_result\n",
        "\n",
        "        #return F.log_softmax(outputImage), y\n",
        "        return outputImage, addition_result"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "152UITgsjjqT"
      },
      "source": [
        "# !pip install torchsummary\n",
        "# from torchsummary import summary\n",
        "# use_cuda = torch.cuda.is_available()\n",
        "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "# model = Net().to(device)\n",
        "# summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJzfocgv0Zcu"
      },
      "source": [
        "**Custom Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OXMyTZenHdx"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "  def __init__(self, isTrain):\n",
        "    if isTrain:\n",
        "      self.data = datasets.MNIST('./data', train=isTrain, download=True, transform=transforms.Compose([transforms.RandomRotation((-5.0, 5.0), fill=(1,)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n",
        "    else:\n",
        "      self.data = datasets.MNIST('./data', train=isTrain, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    r = self.data[index]\n",
        "    image, label = r\n",
        "    random_input = torch.tensor(randint(0,9), dtype=torch.float32)    #torch.randint(0, 10, (1,))\n",
        "    random_target = random_input + label\n",
        "    #print(f'raandom target = {random_target}, random_label={label}, random_input= {random_input} ')\n",
        "    return image, label, random_input, random_target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OrIzu9Eon0V"
      },
      "source": [
        "train_set = CustomDataSet(True)\n",
        "test_set = CustomDataSet(False)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "# next(iter(train_loader))[1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1OooJwAjtc3"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    for batch_idx, (data, target,random_input, random_target) in enumerate(pbar):\n",
        "        data, target, random_input, random_target = data.to(device), target.to(device), random_input.to(device), random_target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, number_output = model(data, random_input)\n",
        "        #print(f' label= {target.shape} image= {data.shape} random_label = {random_target.shape} ')\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss_l1 = F.l1_loss(number_output, random_target)\n",
        "\n",
        "        loss = loss + loss_l1\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "   \n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target, random_input, random_target in test_loader:\n",
        "            # data, target = data.to(device), target.to(device)\n",
        "            data, target, random_input, random_target = data.to(device), target.to(device), random_input.to(device), random_target.to(device)\n",
        "            output, number_output = model(data, random_input)\n",
        "            loss1 = F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            loss_f1 = F.l1_loss(number_output, random_target)\n",
        "            test_loss = loss1 + loss_f1\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNoODT3yjxxS",
        "outputId": "2a4a9fd4-d4a1-4abd-c030-ff0925f71ca4"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 2):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    print('------------------------------------------')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  del sys.path[0]\n",
            "\n",
            "\n",
            "loss=10.742785453796387 batch_id=0 Accuracy=12.50:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=10.742785453796387 batch_id=0 Accuracy=12.50:   0%|          | 1/469 [00:00<00:49,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=9.761452674865723 batch_id=1 Accuracy=11.72:   0%|          | 1/469 [00:00<00:49,  9.40it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=9.273329734802246 batch_id=2 Accuracy=11.72:   0%|          | 1/469 [00:00<00:49,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=8.594279289245605 batch_id=3 Accuracy=11.33:   0%|          | 1/469 [00:00<00:49,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=8.594279289245605 batch_id=3 Accuracy=11.33:   1%|          | 4/469 [00:00<00:41, 11.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=7.170487880706787 batch_id=4 Accuracy=11.09:   1%|          | 4/469 [00:00<00:41, 11.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.906628608703613 batch_id=5 Accuracy=11.98:   1%|          | 4/469 [00:00<00:41, 11.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=7.484557628631592 batch_id=6 Accuracy=12.95:   1%|          | 4/469 [00:00<00:41, 11.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=7.484557628631592 batch_id=6 Accuracy=12.95:   1%|▏         | 7/469 [00:00<00:34, 13.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=8.449234008789062 batch_id=7 Accuracy=14.16:   1%|▏         | 7/469 [00:00<00:34, 13.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=7.015102386474609 batch_id=8 Accuracy=15.54:   1%|▏         | 7/469 [00:00<00:34, 13.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.0729079246521 batch_id=9 Accuracy=17.42:   1%|▏         | 7/469 [00:00<00:34, 13.26it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=6.0729079246521 batch_id=9 Accuracy=17.42:   2%|▏         | 10/469 [00:00<00:31, 14.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.549013137817383 batch_id=10 Accuracy=18.54:   2%|▏         | 10/469 [00:00<00:31, 14.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.605262756347656 batch_id=11 Accuracy=19.08:   2%|▏         | 10/469 [00:00<00:31, 14.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=7.777846813201904 batch_id=12 Accuracy=19.71:   2%|▏         | 10/469 [00:00<00:31, 14.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=7.777846813201904 batch_id=12 Accuracy=19.71:   3%|▎         | 13/469 [00:00<00:27, 16.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=7.078157424926758 batch_id=13 Accuracy=20.65:   3%|▎         | 13/469 [00:00<00:27, 16.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.831760406494141 batch_id=14 Accuracy=21.98:   3%|▎         | 13/469 [00:00<00:27, 16.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.719568729400635 batch_id=15 Accuracy=23.19:   3%|▎         | 13/469 [00:00<00:27, 16.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.719568729400635 batch_id=15 Accuracy=23.19:   3%|▎         | 16/469 [00:00<00:25, 17.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.399343490600586 batch_id=16 Accuracy=24.49:   3%|▎         | 16/469 [00:00<00:25, 17.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.297430038452148 batch_id=17 Accuracy=25.30:   3%|▎         | 16/469 [00:00<00:25, 17.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.297430038452148 batch_id=17 Accuracy=25.30:   4%|▍         | 18/469 [00:00<00:24, 18.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.736948013305664 batch_id=18 Accuracy=26.52:   4%|▍         | 18/469 [00:00<00:24, 18.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.611691474914551 batch_id=19 Accuracy=27.03:   4%|▍         | 18/469 [00:00<00:24, 18.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.1794328689575195 batch_id=20 Accuracy=27.86:   4%|▍         | 18/469 [00:01<00:24, 18.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.1794328689575195 batch_id=20 Accuracy=27.86:   4%|▍         | 21/469 [00:01<00:23, 18.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.685824871063232 batch_id=21 Accuracy=28.37:   4%|▍         | 21/469 [00:01<00:23, 18.85it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=6.138419151306152 batch_id=22 Accuracy=29.35:   4%|▍         | 21/469 [00:01<00:23, 18.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.404592037200928 batch_id=23 Accuracy=30.34:   4%|▍         | 21/469 [00:01<00:23, 18.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=6.404592037200928 batch_id=23 Accuracy=30.34:   5%|▌         | 24/469 [00:01<00:22, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.889750957489014 batch_id=24 Accuracy=31.34:   5%|▌         | 24/469 [00:01<00:22, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.661670684814453 batch_id=25 Accuracy=31.91:   5%|▌         | 24/469 [00:01<00:22, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.661670684814453 batch_id=25 Accuracy=31.91:   6%|▌         | 26/469 [00:01<00:22, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.205238342285156 batch_id=26 Accuracy=32.47:   6%|▌         | 26/469 [00:01<00:22, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.856130123138428 batch_id=27 Accuracy=33.37:   6%|▌         | 26/469 [00:01<00:22, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.856130123138428 batch_id=27 Accuracy=33.37:   6%|▌         | 28/469 [00:01<00:22, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.67288064956665 batch_id=28 Accuracy=33.89:   6%|▌         | 28/469 [00:01<00:22, 19.62it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=5.863471984863281 batch_id=29 Accuracy=34.53:   6%|▌         | 28/469 [00:01<00:22, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.863471984863281 batch_id=29 Accuracy=34.53:   6%|▋         | 30/469 [00:01<00:22, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.459539890289307 batch_id=30 Accuracy=35.16:   6%|▋         | 30/469 [00:01<00:22, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.862765789031982 batch_id=31 Accuracy=36.06:   6%|▋         | 30/469 [00:01<00:22, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.862765789031982 batch_id=31 Accuracy=36.06:   7%|▋         | 32/469 [00:01<00:22, 19.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.442214012145996 batch_id=32 Accuracy=36.74:   7%|▋         | 32/469 [00:01<00:22, 19.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.444216728210449 batch_id=33 Accuracy=37.55:   7%|▋         | 32/469 [00:01<00:22, 19.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.444216728210449 batch_id=33 Accuracy=37.55:   7%|▋         | 34/469 [00:01<00:22, 19.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.317648410797119 batch_id=34 Accuracy=38.21:   7%|▋         | 34/469 [00:01<00:22, 19.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.55970573425293 batch_id=35 Accuracy=38.56:   7%|▋         | 34/469 [00:01<00:22, 19.47it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=5.55970573425293 batch_id=35 Accuracy=38.56:   8%|▊         | 36/469 [00:01<00:22, 19.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.354564666748047 batch_id=36 Accuracy=38.98:   8%|▊         | 36/469 [00:01<00:22, 19.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.177335739135742 batch_id=37 Accuracy=39.43:   8%|▊         | 36/469 [00:01<00:22, 19.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.07696008682251 batch_id=38 Accuracy=40.30:   8%|▊         | 36/469 [00:01<00:22, 19.12it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=5.07696008682251 batch_id=38 Accuracy=40.30:   8%|▊         | 39/469 [00:01<00:21, 19.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.50339412689209 batch_id=39 Accuracy=40.61:   8%|▊         | 39/469 [00:01<00:21, 19.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.216647624969482 batch_id=40 Accuracy=41.22:   8%|▊         | 39/469 [00:02<00:21, 19.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.856367111206055 batch_id=41 Accuracy=41.65:   8%|▊         | 39/469 [00:02<00:21, 19.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.856367111206055 batch_id=41 Accuracy=41.65:   9%|▉         | 42/469 [00:02<00:21, 20.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=5.024282455444336 batch_id=42 Accuracy=42.06:   9%|▉         | 42/469 [00:02<00:21, 20.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.863089084625244 batch_id=43 Accuracy=42.58:   9%|▉         | 42/469 [00:02<00:21, 20.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.882180213928223 batch_id=44 Accuracy=43.02:   9%|▉         | 42/469 [00:02<00:21, 20.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.882180213928223 batch_id=44 Accuracy=43.02:  10%|▉         | 45/469 [00:02<00:20, 20.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.794943809509277 batch_id=45 Accuracy=43.56:  10%|▉         | 45/469 [00:02<00:20, 20.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.429027557373047 batch_id=46 Accuracy=44.25:  10%|▉         | 45/469 [00:02<00:20, 20.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.383391380310059 batch_id=47 Accuracy=44.89:  10%|▉         | 45/469 [00:02<00:20, 20.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.383391380310059 batch_id=47 Accuracy=44.89:  10%|█         | 48/469 [00:02<00:20, 20.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.9553656578063965 batch_id=48 Accuracy=45.06:  10%|█         | 48/469 [00:02<00:20, 20.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.746265411376953 batch_id=49 Accuracy=45.66:  10%|█         | 48/469 [00:02<00:20, 20.67it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.668508529663086 batch_id=50 Accuracy=46.05:  10%|█         | 48/469 [00:02<00:20, 20.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.668508529663086 batch_id=50 Accuracy=46.05:  11%|█         | 51/469 [00:02<00:19, 21.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.696101188659668 batch_id=51 Accuracy=46.42:  11%|█         | 51/469 [00:02<00:19, 21.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.572455883026123 batch_id=52 Accuracy=46.79:  11%|█         | 51/469 [00:02<00:19, 21.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.476675033569336 batch_id=53 Accuracy=47.14:  11%|█         | 51/469 [00:02<00:19, 21.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.476675033569336 batch_id=53 Accuracy=47.14:  12%|█▏        | 54/469 [00:02<00:19, 21.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.589646339416504 batch_id=54 Accuracy=47.50:  12%|█▏        | 54/469 [00:02<00:19, 21.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.265687942504883 batch_id=55 Accuracy=47.89:  12%|█▏        | 54/469 [00:02<00:19, 21.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.470649242401123 batch_id=56 Accuracy=48.26:  12%|█▏        | 54/469 [00:02<00:19, 21.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.470649242401123 batch_id=56 Accuracy=48.26:  12%|█▏        | 57/469 [00:02<00:20, 20.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.286708354949951 batch_id=57 Accuracy=48.79:  12%|█▏        | 57/469 [00:02<00:20, 20.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.58756685256958 batch_id=58 Accuracy=49.21:  12%|█▏        | 57/469 [00:02<00:20, 20.38it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.472892761230469 batch_id=59 Accuracy=49.60:  12%|█▏        | 57/469 [00:02<00:20, 20.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.472892761230469 batch_id=59 Accuracy=49.60:  13%|█▎        | 60/469 [00:02<00:20, 20.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.493564605712891 batch_id=60 Accuracy=50.01:  13%|█▎        | 60/469 [00:03<00:20, 20.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.477489471435547 batch_id=61 Accuracy=50.38:  13%|█▎        | 60/469 [00:03<00:20, 20.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.628326416015625 batch_id=62 Accuracy=50.72:  13%|█▎        | 60/469 [00:03<00:20, 20.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.628326416015625 batch_id=62 Accuracy=50.72:  13%|█▎        | 63/469 [00:03<00:20, 19.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.614271640777588 batch_id=63 Accuracy=51.12:  13%|█▎        | 63/469 [00:03<00:20, 19.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.8291144371032715 batch_id=64 Accuracy=51.49:  13%|█▎        | 63/469 [00:03<00:20, 19.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.8291144371032715 batch_id=64 Accuracy=51.49:  14%|█▍        | 65/469 [00:03<00:20, 19.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.830051898956299 batch_id=65 Accuracy=51.85:  14%|█▍        | 65/469 [00:03<00:20, 19.74it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.642190456390381 batch_id=66 Accuracy=52.18:  14%|█▍        | 65/469 [00:03<00:20, 19.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.167584419250488 batch_id=67 Accuracy=52.65:  14%|█▍        | 65/469 [00:03<00:20, 19.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.167584419250488 batch_id=67 Accuracy=52.65:  14%|█▍        | 68/469 [00:03<00:19, 20.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.117373466491699 batch_id=68 Accuracy=52.94:  14%|█▍        | 68/469 [00:03<00:19, 20.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.670700550079346 batch_id=69 Accuracy=53.28:  14%|█▍        | 68/469 [00:03<00:19, 20.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.2754011154174805 batch_id=70 Accuracy=53.52:  14%|█▍        | 68/469 [00:03<00:19, 20.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.2754011154174805 batch_id=70 Accuracy=53.52:  15%|█▌        | 71/469 [00:03<00:19, 20.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.112074851989746 batch_id=71 Accuracy=53.95:  15%|█▌        | 71/469 [00:03<00:19, 20.40it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.659945487976074 batch_id=72 Accuracy=54.33:  15%|█▌        | 71/469 [00:03<00:19, 20.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.356427192687988 batch_id=73 Accuracy=54.59:  15%|█▌        | 71/469 [00:03<00:19, 20.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.356427192687988 batch_id=73 Accuracy=54.59:  16%|█▌        | 74/469 [00:03<00:19, 19.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9357383251190186 batch_id=74 Accuracy=54.99:  16%|█▌        | 74/469 [00:03<00:19, 19.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.5142130851745605 batch_id=75 Accuracy=55.35:  16%|█▌        | 74/469 [00:03<00:19, 19.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.5142130851745605 batch_id=75 Accuracy=55.35:  16%|█▌        | 76/469 [00:03<00:19, 19.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.293256759643555 batch_id=76 Accuracy=55.77:  16%|█▌        | 76/469 [00:03<00:19, 19.85it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.875335693359375 batch_id=77 Accuracy=56.13:  16%|█▌        | 76/469 [00:03<00:19, 19.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.875335693359375 batch_id=77 Accuracy=56.13:  17%|█▋        | 78/469 [00:03<00:20, 19.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.246338844299316 batch_id=78 Accuracy=56.50:  17%|█▋        | 78/469 [00:03<00:20, 19.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.103826522827148 batch_id=79 Accuracy=56.88:  17%|█▋        | 78/469 [00:03<00:20, 19.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.103826522827148 batch_id=79 Accuracy=56.88:  17%|█▋        | 80/469 [00:03<00:20, 18.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.338195323944092 batch_id=80 Accuracy=57.18:  17%|█▋        | 80/469 [00:04<00:20, 18.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.014773368835449 batch_id=81 Accuracy=57.51:  17%|█▋        | 80/469 [00:04<00:20, 18.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.014773368835449 batch_id=81 Accuracy=57.51:  17%|█▋        | 82/469 [00:04<00:21, 18.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.649683475494385 batch_id=82 Accuracy=57.85:  17%|█▋        | 82/469 [00:04<00:21, 18.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.071767330169678 batch_id=83 Accuracy=58.11:  17%|█▋        | 82/469 [00:04<00:21, 18.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.603780746459961 batch_id=84 Accuracy=58.47:  17%|█▋        | 82/469 [00:04<00:21, 18.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.603780746459961 batch_id=84 Accuracy=58.47:  18%|█▊        | 85/469 [00:04<00:20, 18.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.168509483337402 batch_id=85 Accuracy=58.78:  18%|█▊        | 85/469 [00:04<00:20, 18.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.789350748062134 batch_id=86 Accuracy=59.13:  18%|█▊        | 85/469 [00:04<00:20, 18.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.789350748062134 batch_id=86 Accuracy=59.13:  19%|█▊        | 87/469 [00:04<00:19, 19.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8412599563598633 batch_id=87 Accuracy=59.47:  19%|█▊        | 87/469 [00:04<00:19, 19.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.566333770751953 batch_id=88 Accuracy=59.82:  19%|█▊        | 87/469 [00:04<00:19, 19.17it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.566333770751953 batch_id=88 Accuracy=59.82:  19%|█▉        | 89/469 [00:04<00:19, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.064380645751953 batch_id=89 Accuracy=60.16:  19%|█▉        | 89/469 [00:04<00:19, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.163816928863525 batch_id=90 Accuracy=60.45:  19%|█▉        | 89/469 [00:04<00:19, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.163816928863525 batch_id=90 Accuracy=60.45:  19%|█▉        | 91/469 [00:04<00:19, 19.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.012123107910156 batch_id=91 Accuracy=60.75:  19%|█▉        | 91/469 [00:04<00:19, 19.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.595920085906982 batch_id=92 Accuracy=61.02:  19%|█▉        | 91/469 [00:04<00:19, 19.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.595920085906982 batch_id=92 Accuracy=61.02:  20%|█▉        | 93/469 [00:04<00:19, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.232832908630371 batch_id=93 Accuracy=61.25:  20%|█▉        | 93/469 [00:04<00:19, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.864158868789673 batch_id=94 Accuracy=61.55:  20%|█▉        | 93/469 [00:04<00:19, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.453732967376709 batch_id=95 Accuracy=61.84:  20%|█▉        | 93/469 [00:04<00:19, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.453732967376709 batch_id=95 Accuracy=61.84:  20%|██        | 96/469 [00:04<00:18, 19.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.984910011291504 batch_id=96 Accuracy=62.15:  20%|██        | 96/469 [00:04<00:18, 19.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.099538326263428 batch_id=97 Accuracy=62.39:  20%|██        | 96/469 [00:04<00:18, 19.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.099538326263428 batch_id=97 Accuracy=62.39:  21%|██        | 98/469 [00:04<00:19, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9771995544433594 batch_id=98 Accuracy=62.61:  21%|██        | 98/469 [00:04<00:19, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.15359354019165 batch_id=99 Accuracy=62.89:  21%|██        | 98/469 [00:05<00:19, 19.32it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=4.013854503631592 batch_id=100 Accuracy=63.17:  21%|██        | 98/469 [00:05<00:19, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.013854503631592 batch_id=100 Accuracy=63.17:  22%|██▏       | 101/469 [00:05<00:18, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.2357988357543945 batch_id=101 Accuracy=63.43:  22%|██▏       | 101/469 [00:05<00:18, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.093499183654785 batch_id=102 Accuracy=63.65:  22%|██▏       | 101/469 [00:05<00:18, 19.62it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.093499183654785 batch_id=102 Accuracy=63.65:  22%|██▏       | 103/469 [00:05<00:19, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.140917778015137 batch_id=103 Accuracy=63.90:  22%|██▏       | 103/469 [00:05<00:19, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.114718437194824 batch_id=104 Accuracy=64.15:  22%|██▏       | 103/469 [00:05<00:19, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.976231813430786 batch_id=105 Accuracy=64.42:  22%|██▏       | 103/469 [00:05<00:19, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.976231813430786 batch_id=105 Accuracy=64.42:  23%|██▎       | 106/469 [00:05<00:18, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.711585283279419 batch_id=106 Accuracy=64.70:  23%|██▎       | 106/469 [00:05<00:18, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7886300086975098 batch_id=107 Accuracy=64.97:  23%|██▎       | 106/469 [00:05<00:18, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.924406051635742 batch_id=108 Accuracy=65.23:  23%|██▎       | 106/469 [00:05<00:18, 19.35it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.924406051635742 batch_id=108 Accuracy=65.23:  23%|██▎       | 109/469 [00:05<00:17, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6759440898895264 batch_id=109 Accuracy=65.47:  23%|██▎       | 109/469 [00:05<00:17, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.316041946411133 batch_id=110 Accuracy=65.70:  23%|██▎       | 109/469 [00:05<00:17, 20.05it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6222541332244873 batch_id=111 Accuracy=65.95:  23%|██▎       | 109/469 [00:05<00:17, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6222541332244873 batch_id=111 Accuracy=65.95:  24%|██▍       | 112/469 [00:05<00:17, 20.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7037248611450195 batch_id=112 Accuracy=66.15:  24%|██▍       | 112/469 [00:05<00:17, 20.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8879458904266357 batch_id=113 Accuracy=66.34:  24%|██▍       | 112/469 [00:05<00:17, 20.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8854117393493652 batch_id=114 Accuracy=66.59:  24%|██▍       | 112/469 [00:05<00:17, 20.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8854117393493652 batch_id=114 Accuracy=66.59:  25%|██▍       | 115/469 [00:05<00:17, 20.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.596544027328491 batch_id=115 Accuracy=66.82:  25%|██▍       | 115/469 [00:05<00:17, 20.34it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.847723960876465 batch_id=116 Accuracy=67.05:  25%|██▍       | 115/469 [00:05<00:17, 20.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8139922618865967 batch_id=117 Accuracy=67.29:  25%|██▍       | 115/469 [00:05<00:17, 20.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8139922618865967 batch_id=117 Accuracy=67.29:  25%|██▌       | 118/469 [00:05<00:16, 20.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9692630767822266 batch_id=118 Accuracy=67.47:  25%|██▌       | 118/469 [00:05<00:16, 20.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7868664264678955 batch_id=119 Accuracy=67.66:  25%|██▌       | 118/469 [00:06<00:16, 20.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.913386344909668 batch_id=120 Accuracy=67.85:  25%|██▌       | 118/469 [00:06<00:16, 20.68it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.913386344909668 batch_id=120 Accuracy=67.85:  26%|██▌       | 121/469 [00:06<00:17, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.619649887084961 batch_id=121 Accuracy=68.06:  26%|██▌       | 121/469 [00:06<00:17, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.274016380310059 batch_id=122 Accuracy=68.25:  26%|██▌       | 121/469 [00:06<00:17, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.274016380310059 batch_id=122 Accuracy=68.25:  26%|██▌       | 123/469 [00:06<00:18, 18.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.0885419845581055 batch_id=123 Accuracy=68.47:  26%|██▌       | 123/469 [00:06<00:18, 18.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.700284719467163 batch_id=124 Accuracy=68.65:  26%|██▌       | 123/469 [00:06<00:18, 18.89it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.49981427192688 batch_id=125 Accuracy=68.86:  26%|██▌       | 123/469 [00:06<00:18, 18.89it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.49981427192688 batch_id=125 Accuracy=68.86:  27%|██▋       | 126/469 [00:06<00:17, 19.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.032430171966553 batch_id=126 Accuracy=69.06:  27%|██▋       | 126/469 [00:06<00:17, 19.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.691627025604248 batch_id=127 Accuracy=69.23:  27%|██▋       | 126/469 [00:06<00:17, 19.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.691627025604248 batch_id=127 Accuracy=69.23:  27%|██▋       | 128/469 [00:06<00:17, 19.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6327333450317383 batch_id=128 Accuracy=69.43:  27%|██▋       | 128/469 [00:06<00:17, 19.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.65128231048584 batch_id=129 Accuracy=69.60:  27%|██▋       | 128/469 [00:06<00:17, 19.50it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.65128231048584 batch_id=129 Accuracy=69.60:  28%|██▊       | 130/469 [00:06<00:17, 19.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.104700088500977 batch_id=130 Accuracy=69.78:  28%|██▊       | 130/469 [00:06<00:17, 19.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6341021060943604 batch_id=131 Accuracy=69.96:  28%|██▊       | 130/469 [00:06<00:17, 19.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6341021060943604 batch_id=131 Accuracy=69.96:  28%|██▊       | 132/469 [00:06<00:17, 19.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.848944664001465 batch_id=132 Accuracy=70.12:  28%|██▊       | 132/469 [00:06<00:17, 19.38it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.4940671920776367 batch_id=133 Accuracy=70.31:  28%|██▊       | 132/469 [00:06<00:17, 19.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4940671920776367 batch_id=133 Accuracy=70.31:  29%|██▊       | 134/469 [00:06<00:17, 18.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9288442134857178 batch_id=134 Accuracy=70.48:  29%|██▊       | 134/469 [00:06<00:17, 18.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6862363815307617 batch_id=135 Accuracy=70.65:  29%|██▊       | 134/469 [00:06<00:17, 18.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6862363815307617 batch_id=135 Accuracy=70.65:  29%|██▉       | 136/469 [00:06<00:18, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.055731773376465 batch_id=136 Accuracy=70.83:  29%|██▉       | 136/469 [00:06<00:18, 18.34it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.3920717239379883 batch_id=137 Accuracy=70.99:  29%|██▉       | 136/469 [00:06<00:18, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3920717239379883 batch_id=137 Accuracy=70.99:  29%|██▉       | 138/469 [00:06<00:18, 18.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.906529426574707 batch_id=138 Accuracy=71.17:  29%|██▉       | 138/469 [00:07<00:18, 18.37it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.225615501403809 batch_id=139 Accuracy=71.32:  29%|██▉       | 138/469 [00:07<00:18, 18.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.225615501403809 batch_id=139 Accuracy=71.32:  30%|██▉       | 140/469 [00:07<00:17, 18.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.738297700881958 batch_id=140 Accuracy=71.49:  30%|██▉       | 140/469 [00:07<00:17, 18.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.052295684814453 batch_id=141 Accuracy=71.64:  30%|██▉       | 140/469 [00:07<00:17, 18.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.052295684814453 batch_id=141 Accuracy=71.64:  30%|███       | 142/469 [00:07<00:17, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9535470008850098 batch_id=142 Accuracy=71.81:  30%|███       | 142/469 [00:07<00:17, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6884946823120117 batch_id=143 Accuracy=71.97:  30%|███       | 142/469 [00:07<00:17, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6884946823120117 batch_id=143 Accuracy=71.97:  31%|███       | 144/469 [00:07<00:18, 18.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.012438774108887 batch_id=144 Accuracy=72.13:  31%|███       | 144/469 [00:07<00:18, 18.02it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.63321590423584 batch_id=145 Accuracy=72.30:  31%|███       | 144/469 [00:07<00:18, 18.02it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6124589443206787 batch_id=146 Accuracy=72.46:  31%|███       | 144/469 [00:07<00:18, 18.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6124589443206787 batch_id=146 Accuracy=72.46:  31%|███▏      | 147/469 [00:07<00:16, 19.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.846987009048462 batch_id=147 Accuracy=72.58:  31%|███▏      | 147/469 [00:07<00:16, 19.05it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.7243869304656982 batch_id=148 Accuracy=72.73:  31%|███▏      | 147/469 [00:07<00:16, 19.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7243869304656982 batch_id=148 Accuracy=72.73:  32%|███▏      | 149/469 [00:07<00:16, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4529776573181152 batch_id=149 Accuracy=72.88:  32%|███▏      | 149/469 [00:07<00:16, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4127793312072754 batch_id=150 Accuracy=73.02:  32%|███▏      | 149/469 [00:07<00:16, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4127793312072754 batch_id=150 Accuracy=73.02:  32%|███▏      | 151/469 [00:07<00:17, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.637040853500366 batch_id=151 Accuracy=73.16:  32%|███▏      | 151/469 [00:07<00:17, 18.50it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.7342264652252197 batch_id=152 Accuracy=73.29:  32%|███▏      | 151/469 [00:07<00:17, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.470867156982422 batch_id=153 Accuracy=73.44:  32%|███▏      | 151/469 [00:07<00:17, 18.50it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.470867156982422 batch_id=153 Accuracy=73.44:  33%|███▎      | 154/469 [00:07<00:16, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5350544452667236 batch_id=154 Accuracy=73.60:  33%|███▎      | 154/469 [00:07<00:16, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.302873134613037 batch_id=155 Accuracy=73.72:  33%|███▎      | 154/469 [00:07<00:16, 19.03it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.8870697021484375 batch_id=156 Accuracy=73.86:  33%|███▎      | 154/469 [00:07<00:16, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8870697021484375 batch_id=156 Accuracy=73.86:  33%|███▎      | 157/469 [00:07<00:15, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.230337142944336 batch_id=157 Accuracy=74.02:  33%|███▎      | 157/469 [00:07<00:15, 19.51it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.531991481781006 batch_id=158 Accuracy=74.12:  33%|███▎      | 157/469 [00:08<00:15, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.531991481781006 batch_id=158 Accuracy=74.12:  34%|███▍      | 159/469 [00:08<00:15, 19.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6743340492248535 batch_id=159 Accuracy=74.24:  34%|███▍      | 159/469 [00:08<00:15, 19.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.422739028930664 batch_id=160 Accuracy=74.38:  34%|███▍      | 159/469 [00:08<00:15, 19.60it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.422739028930664 batch_id=160 Accuracy=74.38:  34%|███▍      | 161/469 [00:08<00:17, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.775886297225952 batch_id=161 Accuracy=74.48:  34%|███▍      | 161/469 [00:08<00:17, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5733494758605957 batch_id=162 Accuracy=74.63:  34%|███▍      | 161/469 [00:08<00:17, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6185901165008545 batch_id=163 Accuracy=74.77:  34%|███▍      | 161/469 [00:08<00:17, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6185901165008545 batch_id=163 Accuracy=74.77:  35%|███▍      | 164/469 [00:08<00:15, 19.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4287269115448 batch_id=164 Accuracy=74.88:  35%|███▍      | 164/469 [00:08<00:15, 19.26it/s]   \u001b[A\u001b[A\n",
            "\n",
            "loss=3.2026140689849854 batch_id=165 Accuracy=75.00:  35%|███▍      | 164/469 [00:08<00:15, 19.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2026140689849854 batch_id=165 Accuracy=75.00:  35%|███▌      | 166/469 [00:08<00:16, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8823726177215576 batch_id=166 Accuracy=75.11:  35%|███▌      | 166/469 [00:08<00:16, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.106657028198242 batch_id=167 Accuracy=75.24:  35%|███▌      | 166/469 [00:08<00:16, 18.81it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.106657028198242 batch_id=167 Accuracy=75.24:  36%|███▌      | 168/469 [00:08<00:15, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6296486854553223 batch_id=168 Accuracy=75.35:  36%|███▌      | 168/469 [00:08<00:15, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5536117553710938 batch_id=169 Accuracy=75.46:  36%|███▌      | 168/469 [00:08<00:15, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5536117553710938 batch_id=169 Accuracy=75.46:  36%|███▌      | 170/469 [00:08<00:15, 19.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.693700075149536 batch_id=170 Accuracy=75.59:  36%|███▌      | 170/469 [00:08<00:15, 19.00it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.5015947818756104 batch_id=171 Accuracy=75.71:  36%|███▌      | 170/469 [00:08<00:15, 19.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.54412841796875 batch_id=172 Accuracy=75.83:  36%|███▌      | 170/469 [00:08<00:15, 19.00it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.54412841796875 batch_id=172 Accuracy=75.83:  37%|███▋      | 173/469 [00:08<00:15, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6544978618621826 batch_id=173 Accuracy=75.94:  37%|███▋      | 173/469 [00:08<00:15, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5712082386016846 batch_id=174 Accuracy=76.06:  37%|███▋      | 173/469 [00:08<00:15, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5712082386016846 batch_id=174 Accuracy=76.06:  37%|███▋      | 175/469 [00:08<00:15, 18.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4310224056243896 batch_id=175 Accuracy=76.18:  37%|███▋      | 175/469 [00:08<00:15, 18.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6293880939483643 batch_id=176 Accuracy=76.29:  37%|███▋      | 175/469 [00:08<00:15, 18.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6293880939483643 batch_id=176 Accuracy=76.29:  38%|███▊      | 177/469 [00:09<00:15, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.0619049072265625 batch_id=177 Accuracy=76.40:  38%|███▊      | 177/469 [00:09<00:15, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6680500507354736 batch_id=178 Accuracy=76.49:  38%|███▊      | 177/469 [00:09<00:15, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6680500507354736 batch_id=178 Accuracy=76.49:  38%|███▊      | 179/469 [00:09<00:15, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.775233507156372 batch_id=179 Accuracy=76.61:  38%|███▊      | 179/469 [00:09<00:15, 18.81it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.8958535194396973 batch_id=180 Accuracy=76.71:  38%|███▊      | 179/469 [00:09<00:15, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.859422445297241 batch_id=181 Accuracy=76.83:  38%|███▊      | 179/469 [00:09<00:15, 18.81it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.859422445297241 batch_id=181 Accuracy=76.83:  39%|███▉      | 182/469 [00:09<00:14, 19.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9305007457733154 batch_id=182 Accuracy=76.95:  39%|███▉      | 182/469 [00:09<00:14, 19.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5796351432800293 batch_id=183 Accuracy=77.04:  39%|███▉      | 182/469 [00:09<00:14, 19.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5796351432800293 batch_id=183 Accuracy=77.04:  39%|███▉      | 184/469 [00:09<00:15, 18.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.726992607116699 batch_id=184 Accuracy=77.14:  39%|███▉      | 184/469 [00:09<00:15, 18.53it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.863434314727783 batch_id=185 Accuracy=77.22:  39%|███▉      | 184/469 [00:09<00:15, 18.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.727245807647705 batch_id=186 Accuracy=77.34:  39%|███▉      | 184/469 [00:09<00:15, 18.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.727245807647705 batch_id=186 Accuracy=77.34:  40%|███▉      | 187/469 [00:09<00:14, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.072500228881836 batch_id=187 Accuracy=77.43:  40%|███▉      | 187/469 [00:09<00:14, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.901819944381714 batch_id=188 Accuracy=77.52:  40%|███▉      | 187/469 [00:09<00:14, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.220662832260132 batch_id=189 Accuracy=77.63:  40%|███▉      | 187/469 [00:09<00:14, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.220662832260132 batch_id=189 Accuracy=77.63:  41%|████      | 190/469 [00:09<00:14, 19.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7685139179229736 batch_id=190 Accuracy=77.72:  41%|████      | 190/469 [00:09<00:14, 19.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4719491004943848 batch_id=191 Accuracy=77.80:  41%|████      | 190/469 [00:09<00:14, 19.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4719491004943848 batch_id=191 Accuracy=77.80:  41%|████      | 192/469 [00:09<00:14, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2098517417907715 batch_id=192 Accuracy=77.89:  41%|████      | 192/469 [00:09<00:14, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.671318292617798 batch_id=193 Accuracy=77.98:  41%|████      | 192/469 [00:09<00:14, 19.62it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.671318292617798 batch_id=193 Accuracy=77.98:  41%|████▏     | 194/469 [00:09<00:14, 18.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5556697845458984 batch_id=194 Accuracy=78.08:  41%|████▏     | 194/469 [00:09<00:14, 18.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.570133686065674 batch_id=195 Accuracy=78.17:  41%|████▏     | 194/469 [00:09<00:14, 18.61it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.570133686065674 batch_id=195 Accuracy=78.17:  42%|████▏     | 196/469 [00:09<00:14, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6933910846710205 batch_id=196 Accuracy=78.25:  42%|████▏     | 196/469 [00:10<00:14, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.027144908905029 batch_id=197 Accuracy=78.33:  42%|████▏     | 196/469 [00:10<00:14, 18.58it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=4.027144908905029 batch_id=197 Accuracy=78.33:  42%|████▏     | 198/469 [00:10<00:14, 18.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.257894515991211 batch_id=198 Accuracy=78.42:  42%|████▏     | 198/469 [00:10<00:14, 18.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9589269161224365 batch_id=199 Accuracy=78.50:  42%|████▏     | 198/469 [00:10<00:14, 18.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9589269161224365 batch_id=199 Accuracy=78.50:  43%|████▎     | 200/469 [00:10<00:14, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.482818365097046 batch_id=200 Accuracy=78.58:  43%|████▎     | 200/469 [00:10<00:14, 18.68it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.514669895172119 batch_id=201 Accuracy=78.68:  43%|████▎     | 200/469 [00:10<00:14, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.514669895172119 batch_id=201 Accuracy=78.68:  43%|████▎     | 202/469 [00:10<00:14, 18.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.999483346939087 batch_id=202 Accuracy=78.76:  43%|████▎     | 202/469 [00:10<00:14, 18.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.67264986038208 batch_id=203 Accuracy=78.85:  43%|████▎     | 202/469 [00:10<00:14, 18.60it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.126316547393799 batch_id=204 Accuracy=78.93:  43%|████▎     | 202/469 [00:10<00:14, 18.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.126316547393799 batch_id=204 Accuracy=78.93:  44%|████▎     | 205/469 [00:10<00:14, 18.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.459207773208618 batch_id=205 Accuracy=79.02:  44%|████▎     | 205/469 [00:10<00:14, 18.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.364250898361206 batch_id=206 Accuracy=79.10:  44%|████▎     | 205/469 [00:10<00:14, 18.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.244215726852417 batch_id=207 Accuracy=79.18:  44%|████▎     | 205/469 [00:10<00:14, 18.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.244215726852417 batch_id=207 Accuracy=79.18:  44%|████▍     | 208/469 [00:10<00:13, 19.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9609882831573486 batch_id=208 Accuracy=79.26:  44%|████▍     | 208/469 [00:10<00:13, 19.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.200463056564331 batch_id=209 Accuracy=79.32:  44%|████▍     | 208/469 [00:10<00:13, 19.27it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.200463056564331 batch_id=209 Accuracy=79.32:  45%|████▍     | 210/469 [00:10<00:13, 19.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2918055057525635 batch_id=210 Accuracy=79.41:  45%|████▍     | 210/469 [00:10<00:13, 19.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5255041122436523 batch_id=211 Accuracy=79.49:  45%|████▍     | 210/469 [00:10<00:13, 19.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5255041122436523 batch_id=211 Accuracy=79.49:  45%|████▌     | 212/469 [00:10<00:13, 19.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.603543996810913 batch_id=212 Accuracy=79.57:  45%|████▌     | 212/469 [00:10<00:13, 19.42it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.3219411373138428 batch_id=213 Accuracy=79.64:  45%|████▌     | 212/469 [00:10<00:13, 19.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3219411373138428 batch_id=213 Accuracy=79.64:  46%|████▌     | 214/469 [00:10<00:13, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5499558448791504 batch_id=214 Accuracy=79.72:  46%|████▌     | 214/469 [00:10<00:13, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3705296516418457 batch_id=215 Accuracy=79.80:  46%|████▌     | 214/469 [00:11<00:13, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5702390670776367 batch_id=216 Accuracy=79.87:  46%|████▌     | 214/469 [00:11<00:13, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5702390670776367 batch_id=216 Accuracy=79.87:  46%|████▋     | 217/469 [00:11<00:12, 19.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.915499687194824 batch_id=217 Accuracy=79.95:  46%|████▋     | 217/469 [00:11<00:12, 19.75it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.1887106895446777 batch_id=218 Accuracy=80.02:  46%|████▋     | 217/469 [00:11<00:12, 19.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3700666427612305 batch_id=219 Accuracy=80.08:  46%|████▋     | 217/469 [00:11<00:12, 19.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3700666427612305 batch_id=219 Accuracy=80.08:  47%|████▋     | 220/469 [00:11<00:12, 19.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.637057065963745 batch_id=220 Accuracy=80.15:  47%|████▋     | 220/469 [00:11<00:12, 19.33it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6799066066741943 batch_id=221 Accuracy=80.22:  47%|████▋     | 220/469 [00:11<00:12, 19.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6799066066741943 batch_id=221 Accuracy=80.22:  47%|████▋     | 222/469 [00:11<00:12, 19.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5627613067626953 batch_id=222 Accuracy=80.29:  47%|████▋     | 222/469 [00:11<00:12, 19.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1660420894622803 batch_id=223 Accuracy=80.36:  47%|████▋     | 222/469 [00:11<00:12, 19.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1660420894622803 batch_id=223 Accuracy=80.36:  48%|████▊     | 224/469 [00:11<00:13, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.658498764038086 batch_id=224 Accuracy=80.44:  48%|████▊     | 224/469 [00:11<00:13, 18.81it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.3725130558013916 batch_id=225 Accuracy=80.51:  48%|████▊     | 224/469 [00:11<00:13, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3725130558013916 batch_id=225 Accuracy=80.51:  48%|████▊     | 226/469 [00:11<00:12, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.988351345062256 batch_id=226 Accuracy=80.57:  48%|████▊     | 226/469 [00:11<00:12, 18.91it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.5543718338012695 batch_id=227 Accuracy=80.62:  48%|████▊     | 226/469 [00:11<00:12, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.388154983520508 batch_id=228 Accuracy=80.70:  48%|████▊     | 226/469 [00:11<00:12, 18.91it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.388154983520508 batch_id=228 Accuracy=80.70:  49%|████▉     | 229/469 [00:11<00:12, 19.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3519370555877686 batch_id=229 Accuracy=80.77:  49%|████▉     | 229/469 [00:11<00:12, 19.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5668561458587646 batch_id=230 Accuracy=80.83:  49%|████▉     | 229/469 [00:11<00:12, 19.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5668561458587646 batch_id=230 Accuracy=80.83:  49%|████▉     | 231/469 [00:11<00:13, 17.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6516990661621094 batch_id=231 Accuracy=80.91:  49%|████▉     | 231/469 [00:11<00:13, 17.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.63451886177063 batch_id=232 Accuracy=80.97:  49%|████▉     | 231/469 [00:11<00:13, 17.93it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.63451886177063 batch_id=232 Accuracy=80.97:  50%|████▉     | 233/469 [00:11<00:13, 17.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4092674255371094 batch_id=233 Accuracy=81.04:  50%|████▉     | 233/469 [00:11<00:13, 17.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6437389850616455 batch_id=234 Accuracy=81.10:  50%|████▉     | 233/469 [00:12<00:13, 17.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6437389850616455 batch_id=234 Accuracy=81.10:  50%|█████     | 235/469 [00:12<00:13, 17.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8026187419891357 batch_id=235 Accuracy=81.16:  50%|█████     | 235/469 [00:12<00:13, 17.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4146764278411865 batch_id=236 Accuracy=81.23:  50%|█████     | 235/469 [00:12<00:13, 17.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4146764278411865 batch_id=236 Accuracy=81.23:  51%|█████     | 237/469 [00:12<00:12, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.590867280960083 batch_id=237 Accuracy=81.29:  51%|█████     | 237/469 [00:12<00:12, 18.28it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6839914321899414 batch_id=238 Accuracy=81.36:  51%|█████     | 237/469 [00:12<00:12, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6839914321899414 batch_id=238 Accuracy=81.36:  51%|█████     | 239/469 [00:12<00:12, 18.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4241726398468018 batch_id=239 Accuracy=81.42:  51%|█████     | 239/469 [00:12<00:12, 18.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2952497005462646 batch_id=240 Accuracy=81.48:  51%|█████     | 239/469 [00:12<00:12, 18.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2952497005462646 batch_id=240 Accuracy=81.48:  51%|█████▏    | 241/469 [00:12<00:13, 17.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4177753925323486 batch_id=241 Accuracy=81.55:  51%|█████▏    | 241/469 [00:12<00:13, 17.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.07899284362793 batch_id=242 Accuracy=81.62:  51%|█████▏    | 241/469 [00:12<00:13, 17.50it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=4.07899284362793 batch_id=242 Accuracy=81.62:  52%|█████▏    | 243/469 [00:12<00:12, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.964371919631958 batch_id=243 Accuracy=81.69:  52%|█████▏    | 243/469 [00:12<00:12, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.312615156173706 batch_id=244 Accuracy=81.75:  52%|█████▏    | 243/469 [00:12<00:12, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.312615156173706 batch_id=244 Accuracy=81.75:  52%|█████▏    | 245/469 [00:12<00:12, 17.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.277700662612915 batch_id=245 Accuracy=81.80:  52%|█████▏    | 245/469 [00:12<00:12, 17.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2640440464019775 batch_id=246 Accuracy=81.86:  52%|█████▏    | 245/469 [00:12<00:12, 17.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2640440464019775 batch_id=246 Accuracy=81.86:  53%|█████▎    | 247/469 [00:12<00:12, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.451345443725586 batch_id=247 Accuracy=81.91:  53%|█████▎    | 247/469 [00:12<00:12, 18.28it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.436307668685913 batch_id=248 Accuracy=81.98:  53%|█████▎    | 247/469 [00:12<00:12, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.436307668685913 batch_id=248 Accuracy=81.98:  53%|█████▎    | 249/469 [00:12<00:12, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.714348316192627 batch_id=249 Accuracy=82.05:  53%|█████▎    | 249/469 [00:12<00:12, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.770317792892456 batch_id=250 Accuracy=82.11:  53%|█████▎    | 249/469 [00:12<00:12, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.770317792892456 batch_id=250 Accuracy=82.11:  54%|█████▎    | 251/469 [00:12<00:12, 18.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.463669776916504 batch_id=251 Accuracy=82.16:  54%|█████▎    | 251/469 [00:12<00:12, 18.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8124923706054688 batch_id=252 Accuracy=82.20:  54%|█████▎    | 251/469 [00:13<00:12, 18.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8124923706054688 batch_id=252 Accuracy=82.20:  54%|█████▍    | 253/469 [00:13<00:11, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.036786079406738 batch_id=253 Accuracy=82.26:  54%|█████▍    | 253/469 [00:13<00:11, 18.41it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.5652618408203125 batch_id=254 Accuracy=82.33:  54%|█████▍    | 253/469 [00:13<00:11, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5652618408203125 batch_id=254 Accuracy=82.33:  54%|█████▍    | 255/469 [00:13<00:11, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.362036943435669 batch_id=255 Accuracy=82.38:  54%|█████▍    | 255/469 [00:13<00:11, 18.50it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6491875648498535 batch_id=256 Accuracy=82.44:  54%|█████▍    | 255/469 [00:13<00:11, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6491875648498535 batch_id=256 Accuracy=82.44:  55%|█████▍    | 257/469 [00:13<00:11, 18.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4236419200897217 batch_id=257 Accuracy=82.49:  55%|█████▍    | 257/469 [00:13<00:11, 18.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.361311435699463 batch_id=258 Accuracy=82.54:  55%|█████▍    | 257/469 [00:13<00:11, 18.25it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.361311435699463 batch_id=258 Accuracy=82.54:  55%|█████▌    | 259/469 [00:13<00:11, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7508468627929688 batch_id=259 Accuracy=82.60:  55%|█████▌    | 259/469 [00:13<00:11, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.33073091506958 batch_id=260 Accuracy=82.65:  55%|█████▌    | 259/469 [00:13<00:11, 17.89it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6414074897766113 batch_id=261 Accuracy=82.70:  55%|█████▌    | 259/469 [00:13<00:11, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6414074897766113 batch_id=261 Accuracy=82.70:  56%|█████▌    | 262/469 [00:13<00:11, 18.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5217444896698 batch_id=262 Accuracy=82.75:  56%|█████▌    | 262/469 [00:13<00:11, 18.74it/s]   \u001b[A\u001b[A\n",
            "\n",
            "loss=3.262328863143921 batch_id=263 Accuracy=82.79:  56%|█████▌    | 262/469 [00:13<00:11, 18.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.262328863143921 batch_id=263 Accuracy=82.79:  56%|█████▋    | 264/469 [00:13<00:11, 18.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.259125232696533 batch_id=264 Accuracy=82.86:  56%|█████▋    | 264/469 [00:13<00:11, 18.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5927562713623047 batch_id=265 Accuracy=82.90:  56%|█████▋    | 264/469 [00:13<00:11, 18.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5927562713623047 batch_id=265 Accuracy=82.90:  57%|█████▋    | 266/469 [00:13<00:10, 18.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.831242084503174 batch_id=266 Accuracy=82.95:  57%|█████▋    | 266/469 [00:13<00:10, 18.56it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.2430644035339355 batch_id=267 Accuracy=83.00:  57%|█████▋    | 266/469 [00:13<00:10, 18.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2430644035339355 batch_id=267 Accuracy=83.00:  57%|█████▋    | 268/469 [00:13<00:10, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2704784870147705 batch_id=268 Accuracy=83.04:  57%|█████▋    | 268/469 [00:13<00:10, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3633432388305664 batch_id=269 Accuracy=83.10:  57%|█████▋    | 268/469 [00:13<00:10, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.607342004776001 batch_id=270 Accuracy=83.14:  57%|█████▋    | 268/469 [00:13<00:10, 18.68it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.607342004776001 batch_id=270 Accuracy=83.14:  58%|█████▊    | 271/469 [00:14<00:10, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.306842088699341 batch_id=271 Accuracy=83.19:  58%|█████▊    | 271/469 [00:14<00:10, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.451885938644409 batch_id=272 Accuracy=83.24:  58%|█████▊    | 271/469 [00:14<00:10, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.451885938644409 batch_id=272 Accuracy=83.24:  58%|█████▊    | 273/469 [00:14<00:10, 19.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.711463689804077 batch_id=273 Accuracy=83.29:  58%|█████▊    | 273/469 [00:14<00:10, 19.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.251221179962158 batch_id=274 Accuracy=83.34:  58%|█████▊    | 273/469 [00:14<00:10, 19.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2187273502349854 batch_id=275 Accuracy=83.39:  58%|█████▊    | 273/469 [00:14<00:10, 19.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2187273502349854 batch_id=275 Accuracy=83.39:  59%|█████▉    | 276/469 [00:14<00:09, 19.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6549229621887207 batch_id=276 Accuracy=83.44:  59%|█████▉    | 276/469 [00:14<00:09, 19.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5334713459014893 batch_id=277 Accuracy=83.49:  59%|█████▉    | 276/469 [00:14<00:09, 19.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5334713459014893 batch_id=277 Accuracy=83.49:  59%|█████▉    | 278/469 [00:14<00:09, 19.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.400592565536499 batch_id=278 Accuracy=83.55:  59%|█████▉    | 278/469 [00:14<00:09, 19.18it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.108729600906372 batch_id=279 Accuracy=83.59:  59%|█████▉    | 278/469 [00:14<00:09, 19.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.108729600906372 batch_id=279 Accuracy=83.59:  60%|█████▉    | 280/469 [00:14<00:10, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.0327916145324707 batch_id=280 Accuracy=83.64:  60%|█████▉    | 280/469 [00:14<00:10, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.392307758331299 batch_id=281 Accuracy=83.68:  60%|█████▉    | 280/469 [00:14<00:10, 18.46it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.392307758331299 batch_id=281 Accuracy=83.68:  60%|██████    | 282/469 [00:14<00:10, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7650184631347656 batch_id=282 Accuracy=83.73:  60%|██████    | 282/469 [00:14<00:10, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6478757858276367 batch_id=283 Accuracy=83.78:  60%|██████    | 282/469 [00:14<00:10, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.0541563034057617 batch_id=284 Accuracy=83.82:  60%|██████    | 282/469 [00:14<00:10, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.0541563034057617 batch_id=284 Accuracy=83.82:  61%|██████    | 285/469 [00:14<00:09, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3488712310791016 batch_id=285 Accuracy=83.88:  61%|██████    | 285/469 [00:14<00:09, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5654842853546143 batch_id=286 Accuracy=83.92:  61%|██████    | 285/469 [00:14<00:09, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5654842853546143 batch_id=286 Accuracy=83.92:  61%|██████    | 287/469 [00:14<00:09, 18.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8782742023468018 batch_id=287 Accuracy=83.97:  61%|██████    | 287/469 [00:14<00:09, 18.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.432605266571045 batch_id=288 Accuracy=84.02:  61%|██████    | 287/469 [00:14<00:09, 18.47it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.432605266571045 batch_id=288 Accuracy=84.02:  62%|██████▏   | 289/469 [00:14<00:09, 18.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6167986392974854 batch_id=289 Accuracy=84.06:  62%|██████▏   | 289/469 [00:15<00:09, 18.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7239270210266113 batch_id=290 Accuracy=84.11:  62%|██████▏   | 289/469 [00:15<00:09, 18.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7239270210266113 batch_id=290 Accuracy=84.11:  62%|██████▏   | 291/469 [00:15<00:10, 17.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7146799564361572 batch_id=291 Accuracy=84.15:  62%|██████▏   | 291/469 [00:15<00:10, 17.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5784292221069336 batch_id=292 Accuracy=84.19:  62%|██████▏   | 291/469 [00:15<00:10, 17.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6196773052215576 batch_id=293 Accuracy=84.24:  62%|██████▏   | 291/469 [00:15<00:10, 17.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6196773052215576 batch_id=293 Accuracy=84.24:  63%|██████▎   | 294/469 [00:15<00:09, 18.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.827256917953491 batch_id=294 Accuracy=84.28:  63%|██████▎   | 294/469 [00:15<00:09, 18.22it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6867969036102295 batch_id=295 Accuracy=84.33:  63%|██████▎   | 294/469 [00:15<00:09, 18.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6867969036102295 batch_id=295 Accuracy=84.33:  63%|██████▎   | 296/469 [00:15<00:09, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5597147941589355 batch_id=296 Accuracy=84.37:  63%|██████▎   | 296/469 [00:15<00:09, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3710358142852783 batch_id=297 Accuracy=84.41:  63%|██████▎   | 296/469 [00:15<00:09, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3710358142852783 batch_id=297 Accuracy=84.41:  64%|██████▎   | 298/469 [00:15<00:09, 17.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.22959566116333 batch_id=298 Accuracy=84.45:  64%|██████▎   | 298/469 [00:15<00:09, 17.85it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.3220248222351074 batch_id=299 Accuracy=84.48:  64%|██████▎   | 298/469 [00:15<00:09, 17.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3220248222351074 batch_id=299 Accuracy=84.48:  64%|██████▍   | 300/469 [00:15<00:09, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6362972259521484 batch_id=300 Accuracy=84.53:  64%|██████▍   | 300/469 [00:15<00:09, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6420724391937256 batch_id=301 Accuracy=84.58:  64%|██████▍   | 300/469 [00:15<00:09, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6420724391937256 batch_id=301 Accuracy=84.58:  64%|██████▍   | 302/469 [00:15<00:09, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6863057613372803 batch_id=302 Accuracy=84.62:  64%|██████▍   | 302/469 [00:15<00:09, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.212771415710449 batch_id=303 Accuracy=84.66:  64%|██████▍   | 302/469 [00:15<00:09, 18.29it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.212771415710449 batch_id=303 Accuracy=84.66:  65%|██████▍   | 304/469 [00:15<00:08, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7859017848968506 batch_id=304 Accuracy=84.70:  65%|██████▍   | 304/469 [00:15<00:08, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.390380620956421 batch_id=305 Accuracy=84.74:  65%|██████▍   | 304/469 [00:15<00:08, 18.68it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.186171054840088 batch_id=306 Accuracy=84.78:  65%|██████▍   | 304/469 [00:15<00:08, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.186171054840088 batch_id=306 Accuracy=84.78:  65%|██████▌   | 307/469 [00:15<00:08, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3941426277160645 batch_id=307 Accuracy=84.81:  65%|██████▌   | 307/469 [00:15<00:08, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3683323860168457 batch_id=308 Accuracy=84.85:  65%|██████▌   | 307/469 [00:16<00:08, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3683323860168457 batch_id=308 Accuracy=84.85:  66%|██████▌   | 309/469 [00:16<00:08, 18.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.835559129714966 batch_id=309 Accuracy=84.89:  66%|██████▌   | 309/469 [00:16<00:08, 18.66it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.4560344219207764 batch_id=310 Accuracy=84.93:  66%|██████▌   | 309/469 [00:16<00:08, 18.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4560344219207764 batch_id=310 Accuracy=84.93:  66%|██████▋   | 311/469 [00:16<00:08, 18.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6485133171081543 batch_id=311 Accuracy=84.97:  66%|██████▋   | 311/469 [00:16<00:08, 18.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.57946515083313 batch_id=312 Accuracy=85.01:  66%|██████▋   | 311/469 [00:16<00:08, 18.35it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.1851158142089844 batch_id=313 Accuracy=85.04:  66%|██████▋   | 311/469 [00:16<00:08, 18.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1851158142089844 batch_id=313 Accuracy=85.04:  67%|██████▋   | 314/469 [00:16<00:08, 18.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.134615659713745 batch_id=314 Accuracy=85.08:  67%|██████▋   | 314/469 [00:16<00:08, 18.61it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.3778109550476074 batch_id=315 Accuracy=85.12:  67%|██████▋   | 314/469 [00:16<00:08, 18.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3778109550476074 batch_id=315 Accuracy=85.12:  67%|██████▋   | 316/469 [00:16<00:08, 18.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.342526435852051 batch_id=316 Accuracy=85.15:  67%|██████▋   | 316/469 [00:16<00:08, 18.59it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.8145527839660645 batch_id=317 Accuracy=85.19:  67%|██████▋   | 316/469 [00:16<00:08, 18.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8145527839660645 batch_id=317 Accuracy=85.19:  68%|██████▊   | 318/469 [00:16<00:07, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5142593383789062 batch_id=318 Accuracy=85.23:  68%|██████▊   | 318/469 [00:16<00:07, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.663076400756836 batch_id=319 Accuracy=85.27:  68%|██████▊   | 318/469 [00:16<00:07, 18.90it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.663076400756836 batch_id=319 Accuracy=85.27:  68%|██████▊   | 320/469 [00:16<00:07, 18.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9643964767456055 batch_id=320 Accuracy=85.30:  68%|██████▊   | 320/469 [00:16<00:07, 18.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1722607612609863 batch_id=321 Accuracy=85.35:  68%|██████▊   | 320/469 [00:16<00:07, 18.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1722607612609863 batch_id=321 Accuracy=85.35:  69%|██████▊   | 322/469 [00:16<00:08, 17.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.609506845474243 batch_id=322 Accuracy=85.39:  69%|██████▊   | 322/469 [00:16<00:08, 17.93it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.0214128494262695 batch_id=323 Accuracy=85.43:  69%|██████▊   | 322/469 [00:16<00:08, 17.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.0214128494262695 batch_id=323 Accuracy=85.43:  69%|██████▉   | 324/469 [00:16<00:08, 17.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6278021335601807 batch_id=324 Accuracy=85.47:  69%|██████▉   | 324/469 [00:16<00:08, 17.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2750515937805176 batch_id=325 Accuracy=85.51:  69%|██████▉   | 324/469 [00:16<00:08, 17.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2750515937805176 batch_id=325 Accuracy=85.51:  70%|██████▉   | 326/469 [00:16<00:08, 17.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.345907688140869 batch_id=326 Accuracy=85.55:  70%|██████▉   | 326/469 [00:17<00:08, 17.25it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.392930507659912 batch_id=327 Accuracy=85.59:  70%|██████▉   | 326/469 [00:17<00:08, 17.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.392930507659912 batch_id=327 Accuracy=85.59:  70%|██████▉   | 328/469 [00:17<00:08, 16.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=2.984116792678833 batch_id=328 Accuracy=85.62:  70%|██████▉   | 328/469 [00:17<00:08, 16.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4742391109466553 batch_id=329 Accuracy=85.65:  70%|██████▉   | 328/469 [00:17<00:08, 16.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.402447462081909 batch_id=330 Accuracy=85.69:  70%|██████▉   | 328/469 [00:17<00:08, 16.26it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.402447462081909 batch_id=330 Accuracy=85.69:  71%|███████   | 331/469 [00:17<00:07, 17.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1063361167907715 batch_id=331 Accuracy=85.73:  71%|███████   | 331/469 [00:17<00:07, 17.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6390485763549805 batch_id=332 Accuracy=85.76:  71%|███████   | 331/469 [00:17<00:07, 17.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6390485763549805 batch_id=332 Accuracy=85.76:  71%|███████   | 333/469 [00:17<00:07, 17.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.33854603767395 batch_id=333 Accuracy=85.79:  71%|███████   | 333/469 [00:17<00:07, 17.73it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.6075801849365234 batch_id=334 Accuracy=85.82:  71%|███████   | 333/469 [00:17<00:07, 17.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6075801849365234 batch_id=334 Accuracy=85.82:  71%|███████▏  | 335/469 [00:17<00:07, 17.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.400009870529175 batch_id=335 Accuracy=85.85:  71%|███████▏  | 335/469 [00:17<00:07, 17.36it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.414456367492676 batch_id=336 Accuracy=85.88:  71%|███████▏  | 335/469 [00:17<00:07, 17.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.414456367492676 batch_id=336 Accuracy=85.88:  72%|███████▏  | 337/469 [00:17<00:07, 17.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6594769954681396 batch_id=337 Accuracy=85.91:  72%|███████▏  | 337/469 [00:17<00:07, 17.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5671162605285645 batch_id=338 Accuracy=85.92:  72%|███████▏  | 337/469 [00:17<00:07, 17.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5671162605285645 batch_id=338 Accuracy=85.92:  72%|███████▏  | 339/469 [00:17<00:07, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.270982265472412 batch_id=339 Accuracy=85.96:  72%|███████▏  | 339/469 [00:17<00:07, 18.17it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.363163709640503 batch_id=340 Accuracy=85.99:  72%|███████▏  | 339/469 [00:17<00:07, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.363163709640503 batch_id=340 Accuracy=85.99:  73%|███████▎  | 341/469 [00:17<00:06, 18.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.490231513977051 batch_id=341 Accuracy=86.02:  73%|███████▎  | 341/469 [00:17<00:06, 18.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9073896408081055 batch_id=342 Accuracy=86.05:  73%|███████▎  | 341/469 [00:17<00:06, 18.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.9073896408081055 batch_id=342 Accuracy=86.05:  73%|███████▎  | 343/469 [00:17<00:06, 18.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2185890674591064 batch_id=343 Accuracy=86.08:  73%|███████▎  | 343/469 [00:17<00:06, 18.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1598856449127197 batch_id=344 Accuracy=86.11:  73%|███████▎  | 343/469 [00:18<00:06, 18.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1598856449127197 batch_id=344 Accuracy=86.11:  74%|███████▎  | 345/469 [00:18<00:06, 18.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4379847049713135 batch_id=345 Accuracy=86.15:  74%|███████▎  | 345/469 [00:18<00:06, 18.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.475257635116577 batch_id=346 Accuracy=86.18:  74%|███████▎  | 345/469 [00:18<00:06, 18.52it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.475257635116577 batch_id=346 Accuracy=86.18:  74%|███████▍  | 347/469 [00:18<00:06, 18.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.265989303588867 batch_id=347 Accuracy=86.21:  74%|███████▍  | 347/469 [00:18<00:06, 18.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.32609224319458 batch_id=348 Accuracy=86.24:  74%|███████▍  | 347/469 [00:18<00:06, 18.15it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.32609224319458 batch_id=348 Accuracy=86.24:  74%|███████▍  | 349/469 [00:18<00:06, 17.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6783485412597656 batch_id=349 Accuracy=86.27:  74%|███████▍  | 349/469 [00:18<00:06, 17.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.413857936859131 batch_id=350 Accuracy=86.30:  74%|███████▍  | 349/469 [00:18<00:06, 17.75it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.413857936859131 batch_id=350 Accuracy=86.30:  75%|███████▍  | 351/469 [00:18<00:06, 17.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.394268035888672 batch_id=351 Accuracy=86.33:  75%|███████▍  | 351/469 [00:18<00:06, 17.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.069983959197998 batch_id=352 Accuracy=86.36:  75%|███████▍  | 351/469 [00:18<00:06, 17.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4591996669769287 batch_id=353 Accuracy=86.39:  75%|███████▍  | 351/469 [00:18<00:06, 17.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4591996669769287 batch_id=353 Accuracy=86.39:  75%|███████▌  | 354/469 [00:18<00:06, 18.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.483703374862671 batch_id=354 Accuracy=86.42:  75%|███████▌  | 354/469 [00:18<00:06, 18.16it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.352811813354492 batch_id=355 Accuracy=86.45:  75%|███████▌  | 354/469 [00:18<00:06, 18.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.352811813354492 batch_id=355 Accuracy=86.45:  76%|███████▌  | 356/469 [00:18<00:06, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.0693018436431885 batch_id=356 Accuracy=86.48:  76%|███████▌  | 356/469 [00:18<00:06, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4082658290863037 batch_id=357 Accuracy=86.50:  76%|███████▌  | 356/469 [00:18<00:06, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.310883045196533 batch_id=358 Accuracy=86.53:  76%|███████▌  | 356/469 [00:18<00:06, 17.92it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.310883045196533 batch_id=358 Accuracy=86.53:  77%|███████▋  | 359/469 [00:18<00:05, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.412785768508911 batch_id=359 Accuracy=86.57:  77%|███████▋  | 359/469 [00:18<00:05, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.023130416870117 batch_id=360 Accuracy=86.60:  77%|███████▋  | 359/469 [00:18<00:05, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.023130416870117 batch_id=360 Accuracy=86.60:  77%|███████▋  | 361/469 [00:18<00:05, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.041239023208618 batch_id=361 Accuracy=86.63:  77%|███████▋  | 361/469 [00:18<00:05, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.179398536682129 batch_id=362 Accuracy=86.66:  77%|███████▋  | 361/469 [00:19<00:05, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.179398536682129 batch_id=362 Accuracy=86.66:  77%|███████▋  | 363/469 [00:19<00:05, 17.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.463115930557251 batch_id=363 Accuracy=86.69:  77%|███████▋  | 363/469 [00:19<00:05, 17.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5096728801727295 batch_id=364 Accuracy=86.72:  77%|███████▋  | 363/469 [00:19<00:05, 17.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5096728801727295 batch_id=364 Accuracy=86.72:  78%|███████▊  | 365/469 [00:19<00:05, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2784621715545654 batch_id=365 Accuracy=86.74:  78%|███████▊  | 365/469 [00:19<00:05, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4042210578918457 batch_id=366 Accuracy=86.78:  78%|███████▊  | 365/469 [00:19<00:05, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4042210578918457 batch_id=366 Accuracy=86.78:  78%|███████▊  | 367/469 [00:19<00:06, 16.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1789658069610596 batch_id=367 Accuracy=86.81:  78%|███████▊  | 367/469 [00:19<00:06, 16.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2867274284362793 batch_id=368 Accuracy=86.84:  78%|███████▊  | 367/469 [00:19<00:06, 16.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=2.8216395378112793 batch_id=369 Accuracy=86.87:  78%|███████▊  | 367/469 [00:19<00:06, 16.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=2.8216395378112793 batch_id=369 Accuracy=86.87:  79%|███████▉  | 370/469 [00:19<00:05, 17.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.532763719558716 batch_id=370 Accuracy=86.89:  79%|███████▉  | 370/469 [00:19<00:05, 17.84it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.462756872177124 batch_id=371 Accuracy=86.92:  79%|███████▉  | 370/469 [00:19<00:05, 17.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.462756872177124 batch_id=371 Accuracy=86.92:  79%|███████▉  | 372/469 [00:19<00:05, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.411256790161133 batch_id=372 Accuracy=86.95:  79%|███████▉  | 372/469 [00:19<00:05, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3119595050811768 batch_id=373 Accuracy=86.98:  79%|███████▉  | 372/469 [00:19<00:05, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3119595050811768 batch_id=373 Accuracy=86.98:  80%|███████▉  | 374/469 [00:19<00:05, 17.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7946503162384033 batch_id=374 Accuracy=87.00:  80%|███████▉  | 374/469 [00:19<00:05, 17.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5250720977783203 batch_id=375 Accuracy=87.03:  80%|███████▉  | 374/469 [00:19<00:05, 17.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.287355661392212 batch_id=376 Accuracy=87.06:  80%|███████▉  | 374/469 [00:19<00:05, 17.24it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.287355661392212 batch_id=376 Accuracy=87.06:  80%|████████  | 377/469 [00:19<00:05, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.123452663421631 batch_id=377 Accuracy=87.08:  80%|████████  | 377/469 [00:19<00:05, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1698756217956543 batch_id=378 Accuracy=87.11:  80%|████████  | 377/469 [00:19<00:05, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1698756217956543 batch_id=378 Accuracy=87.11:  81%|████████  | 379/469 [00:19<00:04, 18.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.606058120727539 batch_id=379 Accuracy=87.13:  81%|████████  | 379/469 [00:19<00:04, 18.33it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.1382839679718018 batch_id=380 Accuracy=87.16:  81%|████████  | 379/469 [00:20<00:04, 18.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1382839679718018 batch_id=380 Accuracy=87.16:  81%|████████  | 381/469 [00:20<00:04, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.65425443649292 batch_id=381 Accuracy=87.19:  81%|████████  | 381/469 [00:20<00:04, 18.27it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.483123779296875 batch_id=382 Accuracy=87.22:  81%|████████  | 381/469 [00:20<00:04, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.483123779296875 batch_id=382 Accuracy=87.22:  82%|████████▏ | 383/469 [00:20<00:05, 17.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.050215482711792 batch_id=383 Accuracy=87.25:  82%|████████▏ | 383/469 [00:20<00:05, 17.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5480141639709473 batch_id=384 Accuracy=87.27:  82%|████████▏ | 383/469 [00:20<00:05, 17.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5480141639709473 batch_id=384 Accuracy=87.27:  82%|████████▏ | 385/469 [00:20<00:04, 17.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.743051052093506 batch_id=385 Accuracy=87.29:  82%|████████▏ | 385/469 [00:20<00:04, 17.66it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.035573959350586 batch_id=386 Accuracy=87.31:  82%|████████▏ | 385/469 [00:20<00:04, 17.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.035573959350586 batch_id=386 Accuracy=87.31:  83%|████████▎ | 387/469 [00:20<00:04, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.53580904006958 batch_id=387 Accuracy=87.34:  83%|████████▎ | 387/469 [00:20<00:04, 17.45it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.505458354949951 batch_id=388 Accuracy=87.37:  83%|████████▎ | 387/469 [00:20<00:04, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2515711784362793 batch_id=389 Accuracy=87.39:  83%|████████▎ | 387/469 [00:20<00:04, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2515711784362793 batch_id=389 Accuracy=87.39:  83%|████████▎ | 390/469 [00:20<00:04, 17.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.53475284576416 batch_id=390 Accuracy=87.41:  83%|████████▎ | 390/469 [00:20<00:04, 17.82it/s]  \u001b[A\u001b[A\n",
            "\n",
            "loss=3.7449824810028076 batch_id=391 Accuracy=87.44:  83%|████████▎ | 390/469 [00:20<00:04, 17.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7449824810028076 batch_id=391 Accuracy=87.44:  84%|████████▎ | 392/469 [00:20<00:04, 18.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1515018939971924 batch_id=392 Accuracy=87.46:  84%|████████▎ | 392/469 [00:20<00:04, 18.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.442094087600708 batch_id=393 Accuracy=87.49:  84%|████████▎ | 392/469 [00:20<00:04, 18.11it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.442094087600708 batch_id=393 Accuracy=87.49:  84%|████████▍ | 394/469 [00:20<00:04, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5436201095581055 batch_id=394 Accuracy=87.51:  84%|████████▍ | 394/469 [00:20<00:04, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.502751588821411 batch_id=395 Accuracy=87.54:  84%|████████▍ | 394/469 [00:20<00:04, 18.34it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.502751588821411 batch_id=395 Accuracy=87.54:  84%|████████▍ | 396/469 [00:20<00:03, 18.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2055301666259766 batch_id=396 Accuracy=87.57:  84%|████████▍ | 396/469 [00:20<00:03, 18.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.707500696182251 batch_id=397 Accuracy=87.60:  84%|████████▍ | 396/469 [00:20<00:03, 18.77it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.707500696182251 batch_id=397 Accuracy=87.60:  85%|████████▍ | 398/469 [00:20<00:03, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4994468688964844 batch_id=398 Accuracy=87.62:  85%|████████▍ | 398/469 [00:21<00:03, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.721365213394165 batch_id=399 Accuracy=87.64:  85%|████████▍ | 398/469 [00:21<00:03, 18.68it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.721365213394165 batch_id=399 Accuracy=87.64:  85%|████████▌ | 400/469 [00:21<00:03, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3978495597839355 batch_id=400 Accuracy=87.67:  85%|████████▌ | 400/469 [00:21<00:03, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.0861377716064453 batch_id=401 Accuracy=87.70:  85%|████████▌ | 400/469 [00:21<00:03, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3724825382232666 batch_id=402 Accuracy=87.72:  85%|████████▌ | 400/469 [00:21<00:03, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3724825382232666 batch_id=402 Accuracy=87.72:  86%|████████▌ | 403/469 [00:21<00:03, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.326401710510254 batch_id=403 Accuracy=87.73:  86%|████████▌ | 403/469 [00:21<00:03, 18.50it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.699427604675293 batch_id=404 Accuracy=87.75:  86%|████████▌ | 403/469 [00:21<00:03, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.699427604675293 batch_id=404 Accuracy=87.75:  86%|████████▋ | 405/469 [00:21<00:03, 17.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6676506996154785 batch_id=405 Accuracy=87.78:  86%|████████▋ | 405/469 [00:21<00:03, 17.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.339369535446167 batch_id=406 Accuracy=87.81:  86%|████████▋ | 405/469 [00:21<00:03, 17.64it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.339369535446167 batch_id=406 Accuracy=87.81:  87%|████████▋ | 407/469 [00:21<00:03, 18.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.430816888809204 batch_id=407 Accuracy=87.84:  87%|████████▋ | 407/469 [00:21<00:03, 18.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.004233360290527 batch_id=408 Accuracy=87.86:  87%|████████▋ | 407/469 [00:21<00:03, 18.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=4.004233360290527 batch_id=408 Accuracy=87.86:  87%|████████▋ | 409/469 [00:21<00:03, 18.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.392151117324829 batch_id=409 Accuracy=87.88:  87%|████████▋ | 409/469 [00:21<00:03, 18.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.401203155517578 batch_id=410 Accuracy=87.90:  87%|████████▋ | 409/469 [00:21<00:03, 18.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.401203155517578 batch_id=410 Accuracy=87.90:  88%|████████▊ | 411/469 [00:21<00:03, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4163529872894287 batch_id=411 Accuracy=87.93:  88%|████████▊ | 411/469 [00:21<00:03, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4427762031555176 batch_id=412 Accuracy=87.95:  88%|████████▊ | 411/469 [00:21<00:03, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4427762031555176 batch_id=412 Accuracy=87.95:  88%|████████▊ | 413/469 [00:21<00:03, 17.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.490405797958374 batch_id=413 Accuracy=87.98:  88%|████████▊ | 413/469 [00:21<00:03, 17.49it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.5141985416412354 batch_id=414 Accuracy=88.00:  88%|████████▊ | 413/469 [00:21<00:03, 17.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5141985416412354 batch_id=414 Accuracy=88.00:  88%|████████▊ | 415/469 [00:21<00:03, 17.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=2.9812796115875244 batch_id=415 Accuracy=88.02:  88%|████████▊ | 415/469 [00:21<00:03, 17.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4175307750701904 batch_id=416 Accuracy=88.05:  88%|████████▊ | 415/469 [00:21<00:03, 17.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4175307750701904 batch_id=416 Accuracy=88.05:  89%|████████▉ | 417/469 [00:22<00:02, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.421787738800049 batch_id=417 Accuracy=88.06:  89%|████████▉ | 417/469 [00:22<00:02, 17.89it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.5126235485076904 batch_id=418 Accuracy=88.09:  89%|████████▉ | 417/469 [00:22<00:02, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5126235485076904 batch_id=418 Accuracy=88.09:  89%|████████▉ | 419/469 [00:22<00:02, 17.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.380852460861206 batch_id=419 Accuracy=88.11:  89%|████████▉ | 419/469 [00:22<00:02, 17.87it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.629880666732788 batch_id=420 Accuracy=88.13:  89%|████████▉ | 419/469 [00:22<00:02, 17.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6465189456939697 batch_id=421 Accuracy=88.15:  89%|████████▉ | 419/469 [00:22<00:02, 17.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6465189456939697 batch_id=421 Accuracy=88.15:  90%|████████▉ | 422/469 [00:22<00:02, 18.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6236085891723633 batch_id=422 Accuracy=88.17:  90%|████████▉ | 422/469 [00:22<00:02, 18.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.355102062225342 batch_id=423 Accuracy=88.19:  90%|████████▉ | 422/469 [00:22<00:02, 18.47it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.355102062225342 batch_id=423 Accuracy=88.19:  90%|█████████ | 424/469 [00:22<00:02, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7229533195495605 batch_id=424 Accuracy=88.21:  90%|█████████ | 424/469 [00:22<00:02, 18.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.468092679977417 batch_id=425 Accuracy=88.23:  90%|█████████ | 424/469 [00:22<00:02, 18.03it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.468092679977417 batch_id=425 Accuracy=88.23:  91%|█████████ | 426/469 [00:22<00:02, 17.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5506322383880615 batch_id=426 Accuracy=88.26:  91%|█████████ | 426/469 [00:22<00:02, 17.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.896700382232666 batch_id=427 Accuracy=88.28:  91%|█████████ | 426/469 [00:22<00:02, 17.13it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.896700382232666 batch_id=427 Accuracy=88.28:  91%|█████████▏| 428/469 [00:22<00:02, 16.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8859214782714844 batch_id=428 Accuracy=88.30:  91%|█████████▏| 428/469 [00:22<00:02, 16.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1631522178649902 batch_id=429 Accuracy=88.32:  91%|█████████▏| 428/469 [00:22<00:02, 16.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.1631522178649902 batch_id=429 Accuracy=88.32:  92%|█████████▏| 430/469 [00:22<00:02, 17.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4548373222351074 batch_id=430 Accuracy=88.34:  92%|█████████▏| 430/469 [00:22<00:02, 17.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.146602153778076 batch_id=431 Accuracy=88.37:  92%|█████████▏| 430/469 [00:22<00:02, 17.34it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.146602153778076 batch_id=431 Accuracy=88.37:  92%|█████████▏| 432/469 [00:22<00:02, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.47005033493042 batch_id=432 Accuracy=88.39:  92%|█████████▏| 432/469 [00:22<00:02, 17.45it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.340106248855591 batch_id=433 Accuracy=88.41:  92%|█████████▏| 432/469 [00:22<00:02, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.340106248855591 batch_id=433 Accuracy=88.41:  93%|█████████▎| 434/469 [00:22<00:01, 17.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.583293914794922 batch_id=434 Accuracy=88.43:  93%|█████████▎| 434/469 [00:23<00:01, 17.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.563471794128418 batch_id=435 Accuracy=88.45:  93%|█████████▎| 434/469 [00:23<00:01, 17.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.563471794128418 batch_id=435 Accuracy=88.45:  93%|█████████▎| 436/469 [00:23<00:01, 16.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5782628059387207 batch_id=436 Accuracy=88.47:  93%|█████████▎| 436/469 [00:23<00:01, 16.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4353628158569336 batch_id=437 Accuracy=88.50:  93%|█████████▎| 436/469 [00:23<00:01, 16.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4353628158569336 batch_id=437 Accuracy=88.50:  93%|█████████▎| 438/469 [00:23<00:01, 17.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8860714435577393 batch_id=438 Accuracy=88.52:  93%|█████████▎| 438/469 [00:23<00:01, 17.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3508694171905518 batch_id=439 Accuracy=88.55:  93%|█████████▎| 438/469 [00:23<00:01, 17.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6905300617218018 batch_id=440 Accuracy=88.56:  93%|█████████▎| 438/469 [00:23<00:01, 17.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6905300617218018 batch_id=440 Accuracy=88.56:  94%|█████████▍| 441/469 [00:23<00:01, 18.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2909436225891113 batch_id=441 Accuracy=88.58:  94%|█████████▍| 441/469 [00:23<00:01, 18.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4899184703826904 batch_id=442 Accuracy=88.59:  94%|█████████▍| 441/469 [00:23<00:01, 18.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4899184703826904 batch_id=442 Accuracy=88.59:  94%|█████████▍| 443/469 [00:23<00:01, 17.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.482032299041748 batch_id=443 Accuracy=88.62:  94%|█████████▍| 443/469 [00:23<00:01, 17.04it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.8345212936401367 batch_id=444 Accuracy=88.63:  94%|█████████▍| 443/469 [00:23<00:01, 17.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3300576210021973 batch_id=445 Accuracy=88.65:  94%|█████████▍| 443/469 [00:23<00:01, 17.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.3300576210021973 batch_id=445 Accuracy=88.65:  95%|█████████▌| 446/469 [00:23<00:01, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4354116916656494 batch_id=446 Accuracy=88.67:  95%|█████████▌| 446/469 [00:23<00:01, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4737768173217773 batch_id=447 Accuracy=88.69:  95%|█████████▌| 446/469 [00:23<00:01, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4737768173217773 batch_id=447 Accuracy=88.69:  96%|█████████▌| 448/469 [00:23<00:01, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.438957929611206 batch_id=448 Accuracy=88.71:  96%|█████████▌| 448/469 [00:23<00:01, 18.58it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.840510606765747 batch_id=449 Accuracy=88.73:  96%|█████████▌| 448/469 [00:23<00:01, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.840510606765747 batch_id=449 Accuracy=88.73:  96%|█████████▌| 450/469 [00:23<00:01, 17.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.365518093109131 batch_id=450 Accuracy=88.75:  96%|█████████▌| 450/469 [00:23<00:01, 17.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5415704250335693 batch_id=451 Accuracy=88.77:  96%|█████████▌| 450/469 [00:23<00:01, 17.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.052502155303955 batch_id=452 Accuracy=88.80:  96%|█████████▌| 450/469 [00:24<00:01, 17.62it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.052502155303955 batch_id=452 Accuracy=88.80:  97%|█████████▋| 453/469 [00:24<00:00, 18.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5708117485046387 batch_id=453 Accuracy=88.82:  97%|█████████▋| 453/469 [00:24<00:00, 18.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.914121150970459 batch_id=454 Accuracy=88.84:  97%|█████████▋| 453/469 [00:24<00:00, 18.35it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.914121150970459 batch_id=454 Accuracy=88.84:  97%|█████████▋| 455/469 [00:24<00:00, 18.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.0090579986572266 batch_id=455 Accuracy=88.86:  97%|█████████▋| 455/469 [00:24<00:00, 18.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.458484649658203 batch_id=456 Accuracy=88.88:  97%|█████████▋| 455/469 [00:24<00:00, 18.42it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.458484649658203 batch_id=456 Accuracy=88.88:  97%|█████████▋| 457/469 [00:24<00:00, 18.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.4755074977874756 batch_id=457 Accuracy=88.90:  97%|█████████▋| 457/469 [00:24<00:00, 18.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2947890758514404 batch_id=458 Accuracy=88.92:  97%|█████████▋| 457/469 [00:24<00:00, 18.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2947890758514404 batch_id=458 Accuracy=88.92:  98%|█████████▊| 459/469 [00:24<00:00, 18.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.2557568550109863 batch_id=459 Accuracy=88.94:  98%|█████████▊| 459/469 [00:24<00:00, 18.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.573194742202759 batch_id=460 Accuracy=88.95:  98%|█████████▊| 459/469 [00:24<00:00, 18.09it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.573194742202759 batch_id=460 Accuracy=88.95:  98%|█████████▊| 461/469 [00:24<00:00, 17.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.7032580375671387 batch_id=461 Accuracy=88.97:  98%|█████████▊| 461/469 [00:24<00:00, 17.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.464536666870117 batch_id=462 Accuracy=88.99:  98%|█████████▊| 461/469 [00:24<00:00, 17.41it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.464536666870117 batch_id=462 Accuracy=88.99:  99%|█████████▊| 463/469 [00:24<00:00, 17.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.519695281982422 batch_id=463 Accuracy=89.01:  99%|█████████▊| 463/469 [00:24<00:00, 17.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6336188316345215 batch_id=464 Accuracy=89.03:  99%|█████████▊| 463/469 [00:24<00:00, 17.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.6336188316345215 batch_id=464 Accuracy=89.03:  99%|█████████▉| 465/469 [00:24<00:00, 17.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.5317575931549072 batch_id=465 Accuracy=89.04:  99%|█████████▉| 465/469 [00:24<00:00, 17.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.488359212875366 batch_id=466 Accuracy=89.06:  99%|█████████▉| 465/469 [00:24<00:00, 17.70it/s] \u001b[A\u001b[A\n",
            "\n",
            "loss=3.488359212875366 batch_id=466 Accuracy=89.06: 100%|█████████▉| 467/469 [00:24<00:00, 16.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "loss=3.8963980674743652 batch_id=467 Accuracy=89.07: 100%|█████████▉| 467/469 [00:24<00:00, 16.96it/s]\u001b[A\u001b[A/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  del sys.path[0]\n",
            "\n",
            "\n",
            "loss=3.551478862762451 batch_id=468 Accuracy=89.09: 100%|██████████| 469/469 [00:24<00:00, 18.80it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0007, Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3pYz3xlM_1b",
        "outputId": "439f4c27-1e47-4ca0-b855-7c5fb8b390a5"
      },
      "source": [
        "next(iter(train_set))[0].shape, next(iter(train_set))[2]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), tensor(8.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKPZ7RtYNYHq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}