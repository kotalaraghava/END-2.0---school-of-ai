{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA P2S3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotalaraghava/END-2.0---school-of-ai/blob/master/EVA_P2S3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('./sample_data/text.txt', 'r').read()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0b8ca0-0375-4bc6-efcf-a903bcca8c62"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1+np.exp(-x))# write your code here\n",
        "\n",
        "def dsigmoid(y):\n",
        "  # s = sigmoid(y) # derivative of sigmoid function\n",
        "  return y * (1-y)# write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)# write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1- y **2# write your code here"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_V-KstVvE7I",
        "outputId": "8dc70188-8bd5-4417-90c0-182a3cd6081c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sigmoid(0), dsigmoid(sigmoid(0)), tanh(dsigmoid(sigmoid(0))), dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.25, 0.24491866240370913, 0.940014848806378)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size# write your code here\n",
        "size_b = z_size# write your code here\n",
        "size_c = X_size# write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEV1cbX03rIt",
        "outputId": "380519a1-0786-49e3-a925-55ec916e7c0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnWeABM4IyY",
        "outputId": "08e94b66-13d3-4a53-9d27-3d12a1b3f347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "566a21d1-c0e6-4517-d2e2-5038a5042171"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " fuuppring to the Arizona State Tasidays and or id there evuch, and screenas, but theme coronavirus, often with sicd pabe the know work, to screed to it caketsing in isolation. \n",
            "\n",
            "Avet firl and United S \n",
            "----\n",
            "iter 49900, loss 5.802795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnmLmham4QEi"
      },
      "source": [
        ""
      ],
      "execution_count": 63,
      "outputs": []
    }
  ]
}